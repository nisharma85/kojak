{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import logging\n",
    "from gensim import corpora, models, similarities\n",
    "from pprint import pprint\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "from sklearn import feature_extraction\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.learning_curve import learning_curve\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score,  roc_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import svm, grid_search\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import sklearn\n",
    "import mpld3\n",
    "import lda\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# reload(sys)  \n",
    "# sys.setdefaultencoding('Cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bl=pd.read_csv('data/bl.csv', na_values='DK', encoding='latin-1')\n",
    "fy15q3= pd.read_csv('data/fy15q3.csv', na_values='DK', encoding='latin-1')\n",
    "fy16= pd.read_csv('data/fy16.csv', na_values='DK', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3068"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fy16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fy16['geo']=fy16['geo'].fillna('NaM')\n",
    "fy15q3['Geo']=fy15q3['Geo'].fillna('NaM')\n",
    "bl['Region : Region (Global Area)']=bl['Region : Region (Global Area)'].fillna('NaM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fy16.loc[fy16['translation.to.english.for..ltr.comment'].isnull(),\n",
    "       'comment'] = fy16['ltr.comment']\n",
    "\n",
    "fy15q3.loc[fy15q3['translation_to_1_q_ca_ltrfollowup_reporting_comment'].isnull(),\n",
    "       'comment'] = fy15q3['LTR Comment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fy16_1=fy16[[ 'email', 'geo','segment', 'role2', 'ltr','acct.mgt',\n",
    "      'license.contract', 'best.practice', 'implement', 'product.qual', 'functionality', 'ease.of.use', \n",
    "      'tech.support','fiscalyear', 'quarter', 'ltr.comment','ltr_comment_theme1', 'ltr_comment_theme2',\n",
    "      'ltr_comment_theme3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shani16/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "fy15q3['responsedate'][1061:1064]='NaN'\n",
    "fy15q3['responsedate']=pd.to_datetime(pd.Series(fy15q3['responsedate']), format=\"%m/%d/%y %H:%M\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fy15q3['responseyr'], fy15q3['rmth'] = fy15q3['responsedate'].dt.year, fy15q3['responsedate'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fy15q3['fiscalyear'] = 'NaN'\n",
    "fy15q3.loc[fy15q3['rmth'] > 4, 'fiscalyear'] = \"FY15\"\n",
    "fy15q3['quarter']=\"Q3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fy15q3_1=fy15q3[[ 'Contact Email', 'Geo','Segment', 'Respondent Role', 'LTR', \n",
    "                 'INS - Overall Account Management',\n",
    "      'INS - Licensing and Contract Process', 'INS - Best Practices Advice', 'INS - Product Implementation Process',\n",
    "                 'INS - Overall Quality of Products', 'INS - Overall Functionality of Products', \n",
    "                 'INS - Overall Ease of Use', \n",
    "      'INS - Ability to Get Technical Support','fiscalyear', 'quarter', 'comment','LTR_Comment_Theme1 ',\n",
    "                 'LTR_Comment_Theme2',\n",
    "      'LTR_Comment_Theme3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fy15q3_1.columns=['email', 'geo','segment', 'role2', 'ltr','acct.mgt',\n",
    "      'license.contract', 'best.practice', 'implement', 'product.qual', 'functionality', 'ease.of.use', \n",
    "      'tech.support','fiscalyear', 'quarter', 'ltr.comment','ltr_comment_theme1', 'ltr_comment_theme2',\n",
    "      'ltr_comment_theme3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bl.loc[bl['What can CA Technologies do to improve your likelihood to recommend us? - Translated'].isnull(),\n",
    "       'new'] = bl['What can CA Technologies do to improve your likelihood to recommend us?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bl.loc[bl['What one thing can CA Technologies to improve your likelihod to recommend us? Translated'].isnull(),\n",
    "       'new1'] = bl['What one thing can CA Technologies to improve your likelihod to recommend us?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bl.loc[bl['What can CA Technologies do to improve your likelihood to recommend us? - Translated.1'].isnull(),\n",
    "       'new2'] = bl['What can CA Technologies do to improve your likelihood to recommend us?.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bl['ltr.comment']=pd.concat([bl['new'].dropna(), bl['new1'].dropna(), bl['new2'].dropna() ]).reindex_like(bl)\n",
    "bl['theme1']=pd.concat([bl['LTR_Promoters_Theme1'].dropna(), bl['LTR_Passives_Theme1'].dropna(), bl['LTR_Detractors_Theme1'].dropna() ]).reindex_like(bl)\n",
    "bl['theme2']=pd.concat([bl['LTR_Promoters_Theme2'].dropna(), bl['LTR_Passives_Theme2'].dropna(), bl['LTR_Detractors_Theme2'].dropna() ]).reindex_like(bl)\n",
    "bl['theme3']=pd.concat([bl['LTR_Promoters_Theme3'].dropna(), bl['LTR_Passives_Theme3 : LTR_Passives_Theme3'].dropna(), bl['LTR_Detractors_Theme3'].dropna() ]).reindex_like(bl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# bl.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bl_1=bl[[ 'ContactEmail : ContactEmail', 'Region : Region (Global Area)','AccountType : AccountType',\n",
    "         'Role_New_WP : Role', 'How likely are you to recommend CA Technologies ', \n",
    "        u'Overall Account Management\\xe6\\xe6\\xe6\\xe6\\xe6\\xe6\\xe6\\xe6\\xe6\\xe6\\xe6\\xe6\\xe6\\xe6',\n",
    "      'Licensing and contract process', 'Best-practices advice', 'Product implementation process',\n",
    "                 'Overall quality of products', 'Overall functionality of products', \n",
    "                 'Overall ease of use of CA Technologies products', 'Ability to get technical support from CA Technologies',\n",
    "         'Fiscal Year', 'Quarter', \n",
    "         'ltr.comment','theme1', 'theme2', 'theme3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bl_1.columns=['email', 'geo','segment', 'role2', 'ltr','acct.mgt',\n",
    "      'license.contract', 'best.practice', 'implement', 'product.qual', 'functionality', 'ease.of.use', \n",
    "      'tech.support','fiscalyear', 'quarter', 'ltr.comment','ltr_comment_theme1', 'ltr_comment_theme2',\n",
    "      'ltr_comment_theme3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shani16/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "fy15q3_1['role2'] = fy15q3_1['role2'].map({'End User': 'END_USER', 'Influencer': 'DM/INF', 'Decision Maker': 'DM/INF', 'Recommender': 'END_USER'   })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shani16/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "bl_1['role2'] = bl_1['role2'].map({'END': 'END_USER', 'INF': 'DM/INF', 'DM': 'DM/INF', 'PRO': 'END_USER'   })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FY16    3068\n",
       "Name: fiscalyear, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fy16_1['fiscalyear'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frames= [bl_1, fy15q3_1, fy16_1]\n",
    "df=pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df[pd.notnull(df['ltr.comment'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'email', u'geo', u'segment', u'role2', u'ltr', u'acct.mgt',\n",
       "       u'license.contract', u'best.practice', u'implement', u'product.qual',\n",
       "       u'functionality', u'ease.of.use', u'tech.support', u'fiscalyear',\n",
       "       u'quarter', u'ltr.comment', u'ltr_comment_theme1',\n",
       "       u'ltr_comment_theme2', u'ltr_comment_theme3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df[(df.geo == 'NaM') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>geo</th>\n",
       "      <th>segment</th>\n",
       "      <th>role2</th>\n",
       "      <th>ltr</th>\n",
       "      <th>acct.mgt</th>\n",
       "      <th>license.contract</th>\n",
       "      <th>best.practice</th>\n",
       "      <th>implement</th>\n",
       "      <th>product.qual</th>\n",
       "      <th>functionality</th>\n",
       "      <th>ease.of.use</th>\n",
       "      <th>tech.support</th>\n",
       "      <th>fiscalyear</th>\n",
       "      <th>quarter</th>\n",
       "      <th>ltr.comment</th>\n",
       "      <th>ltr_comment_theme1</th>\n",
       "      <th>ltr_comment_theme2</th>\n",
       "      <th>ltr_comment_theme3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alain.z.cote@dgag.ca</td>\n",
       "      <td>NaM</td>\n",
       "      <td>Named</td>\n",
       "      <td>END_USER</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6.772884</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>FY14</td>\n",
       "      <td>Q2</td>\n",
       "      <td>Improve the quality, stability and integration...</td>\n",
       "      <td>Product_Quality</td>\n",
       "      <td>Product_Scope</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>matt.merchant@ge.com</td>\n",
       "      <td>NaM</td>\n",
       "      <td>Platinum</td>\n",
       "      <td>DM/INF</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>7.313038</td>\n",
       "      <td>7.602971</td>\n",
       "      <td>FY14</td>\n",
       "      <td>Q2</td>\n",
       "      <td>ITSM space is best for CA. Still work to be do...</td>\n",
       "      <td>Product_Scope</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chris.schwind@firstdata.com</td>\n",
       "      <td>NaM</td>\n",
       "      <td>Platinum</td>\n",
       "      <td>END_USER</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>6.772884</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>FY14</td>\n",
       "      <td>Q2</td>\n",
       "      <td>Service Assurance, Mainframe tools, Scheduling...</td>\n",
       "      <td>Product_Scope</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dominic.nguyen@ge.com</td>\n",
       "      <td>NaM</td>\n",
       "      <td>Platinum</td>\n",
       "      <td>END_USER</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>6.772884</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>FY14</td>\n",
       "      <td>Q2</td>\n",
       "      <td>Needs to get product more stable and less bugs</td>\n",
       "      <td>Product_Quality</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mz1223@att.com</td>\n",
       "      <td>NaM</td>\n",
       "      <td>Platinum</td>\n",
       "      <td>END_USER</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6.772884</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>FY14</td>\n",
       "      <td>Q2</td>\n",
       "      <td>We primarily use Introscope under the APM suit...</td>\n",
       "      <td>Contracts_Negotiations</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         email  geo   segment     role2  ltr  acct.mgt  \\\n",
       "1         alain.z.cote@dgag.ca  NaM     Named  END_USER    0         9   \n",
       "2         matt.merchant@ge.com  NaM  Platinum    DM/INF    9        10   \n",
       "3  chris.schwind@firstdata.com  NaM  Platinum  END_USER    9        10   \n",
       "4        dominic.nguyen@ge.com  NaM  Platinum  END_USER    3         8   \n",
       "5               mz1223@att.com  NaM  Platinum  END_USER    7         8   \n",
       "\n",
       "   license.contract  best.practice  implement  product.qual  functionality  \\\n",
       "1          6.772884              4          2             0              6   \n",
       "2          8.000000              9         10             9              9   \n",
       "3          6.772884              9          7             8              8   \n",
       "4          6.772884              7          3             2              4   \n",
       "5          6.772884             10         10             9             10   \n",
       "\n",
       "   ease.of.use  tech.support fiscalyear quarter  \\\n",
       "1     0.000000      0.000000       FY14      Q2   \n",
       "2     7.313038      7.602971       FY14      Q2   \n",
       "3     8.000000      8.000000       FY14      Q2   \n",
       "4     2.000000      3.000000       FY14      Q2   \n",
       "5     8.000000      2.000000       FY14      Q2   \n",
       "\n",
       "                                         ltr.comment      ltr_comment_theme1  \\\n",
       "1  Improve the quality, stability and integration...         Product_Quality   \n",
       "2  ITSM space is best for CA. Still work to be do...           Product_Scope   \n",
       "3  Service Assurance, Mainframe tools, Scheduling...           Product_Scope   \n",
       "4     Needs to get product more stable and less bugs         Product_Quality   \n",
       "5  We primarily use Introscope under the APM suit...  Contracts_Negotiations   \n",
       "\n",
       "  ltr_comment_theme2 ltr_comment_theme3  \n",
       "1      Product_Scope                NaN  \n",
       "2                NaN                NaN  \n",
       "3                NaN                NaN  \n",
       "4                NaN                NaN  \n",
       "5                NaN                NaN  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.772884     1768\n",
       "8.000000      263\n",
       "7.000000      197\n",
       "9.000000      173\n",
       "6.000000      132\n",
       "10.000000     107\n",
       "5.000000      103\n",
       "4.000000       48\n",
       "3.000000       42\n",
       "2.000000       41\n",
       "1.000000       26\n",
       "0.000000       26\n",
       "Name: license.contract, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['license.contract'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['ltr.comment']=df['ltr.comment'].str.replace(r'\\?', '')\n",
    "df['ltr.comment']=df['ltr.comment'].str.replace(r'\\r', '')\n",
    "df['ltr.comment']=df['ltr.comment'].str.replace(r'\\#NAME', '')\n",
    "df['ltr.comment']=df['ltr.comment'].str.replace(r'n/a', '')\n",
    "df['ltr.comment']=df['ltr.comment'].str.replace(r'na', '')\n",
    "df['ltr.comment']=df['ltr.comment'].str.replace(r'-', '')\n",
    "df['ltr.comment']=df['ltr.comment'].str.replace(r'.', '')\n",
    "df['ltr.comment']=df['ltr.comment'].str.replace(r'___', '')\n",
    "df['ltr.comment']=df['ltr.comment'].str.replace(r'_', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FY16    1236\n",
       "FY15     987\n",
       "FY14     701\n",
       "Name: fiscalyear, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['fiscalyear'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['email',\n",
       " 'geo',\n",
       " 'segment',\n",
       " 'role2',\n",
       " 'ltr',\n",
       " 'acct.mgt',\n",
       " 'license.contract',\n",
       " 'best.practice',\n",
       " 'implement',\n",
       " 'product.qual',\n",
       " 'functionality',\n",
       " 'ease.of.use',\n",
       " 'tech.support',\n",
       " 'fiscalyear',\n",
       " 'quarter',\n",
       " 'ltr.comment',\n",
       " 'ltr_comment_theme1',\n",
       " 'ltr_comment_theme2',\n",
       " 'ltr_comment_theme3']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns=[ 'email',\n",
    " 'geo',\n",
    " 'segment',\n",
    " 'role2',\n",
    " 'ltr',\n",
    " 'acctmgt',\n",
    " 'licensecontract',\n",
    " 'bestpractice',\n",
    " 'implement',\n",
    " 'productqual',\n",
    " 'functionality',\n",
    " 'easeofuse',\n",
    " 'techsupport',\n",
    " 'fiscalyear',\n",
    " 'quarter',\n",
    " 'ltrcomment',\n",
    " 'ltr_comment_theme1',\n",
    " 'ltr_comment_theme2',\n",
    " 'ltr_comment_theme3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords += ['.', ',', '(', ')', \"'\", '\"', 'ca', 'customer', 'need', 'products', 'would', 'like', 'de', 'sure',\n",
    "             'nothing', 'cost', 'us', 'use', 'get', 'make', 'needs', 'need', 'customer','customers',\n",
    "              'would', 'get', 'like', '30', 'also', 'many', 'day'\n",
    "             '30', '1000', '10', '06', '100', '1000', '1000s', '11', '12', '13','14', '15', '18', '19', '1sr', '200',\n",
    "             '2005', '2009', '2011', '2012', '20126', '2014', '2015', 'vs', 'you', 'we', 'know', 'even', 'see', 'zuk', \n",
    "              'fen' , 'gartner', 'rules', 'cas', 'year', 'nothing', 'look', 'sure', 'solutions', 'better', 'sure' ,\n",
    "              'line', 'one','clear', 'products', 'product', 'tool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_clusters = 50  # sp.unique(labels).shape[0]\n",
    "\n",
    "import nltk.stem\n",
    "english_stemmer = nltk.stem.SnowballStemmer('english')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(TfidfVectorizer, self).build_analyzer()\n",
    "        return lambda doc: (english_stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "vectorizer = StemmedTfidfVectorizer(min_df=10, max_df=0.5, ngram_range=(1, 5),\n",
    "                                    stop_words=stopwords, decode_error='ignore'\n",
    "                                    )\n",
    "vectorized = vectorizer.fit_transform(df.ltrcomment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>access</th>\n",
       "      <th>access mag</th>\n",
       "      <th>account</th>\n",
       "      <th>account mag</th>\n",
       "      <th>account rep</th>\n",
       "      <th>account team</th>\n",
       "      <th>accur</th>\n",
       "      <th>acquir</th>\n",
       "      <th>...</th>\n",
       "      <th>will</th>\n",
       "      <th>willing</th>\n",
       "      <th>within</th>\n",
       "      <th>without</th>\n",
       "      <th>work</th>\n",
       "      <th>work wel</th>\n",
       "      <th>workload</th>\n",
       "      <th>world</th>\n",
       "      <th>year</th>\n",
       "      <th>yet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 706 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abil  abl  access  access mag  account  account mag  account rep  \\\n",
       "0     0    0       0           0        0            0            0   \n",
       "\n",
       "   account team  accur  acquir ...   will  willing  within  without  work  \\\n",
       "0             0      0       0 ...      0        0       0        0     0   \n",
       "\n",
       "   work wel  workload  world  year  yet  \n",
       "0         0         0      0     0    0  \n",
       "\n",
       "[1 rows x 706 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature= vectorized.toarray()\n",
    "feature_df = pd.DataFrame(feature, columns=vectorizer.get_feature_names())\n",
    "feature_df[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shani16/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>support</td>\n",
       "      <td>159.482401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>servic</td>\n",
       "      <td>109.603011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>improv</td>\n",
       "      <td>95.190834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>price</td>\n",
       "      <td>66.266098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>work</td>\n",
       "      <td>60.142100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>provid</td>\n",
       "      <td>59.170976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>integr</td>\n",
       "      <td>56.479961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>technolog</td>\n",
       "      <td>55.044660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>issu</td>\n",
       "      <td>54.115881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>team</td>\n",
       "      <td>52.515629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word        freq\n",
       "610    support  159.482401\n",
       "553     servic  109.603011\n",
       "292     improv   95.190834\n",
       "465      price   66.266098\n",
       "700       work   60.142100\n",
       "484     provid   59.170976\n",
       "309     integr   56.479961\n",
       "627  technolog   55.044660\n",
       "320       issu   54.115881\n",
       "620       team   52.515629"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequency = feature_df.sum().reset_index()\n",
    "word_frequency.columns=['word', 'freq']\n",
    "\n",
    "word_frequency=word_frequency.sort(columns='freq', ascending= False)\n",
    "word_frequency[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "model = KMeans (n_clusters=30, init= 'k-means++', max_iter=100, n_init=1, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = KMeans (n_clusters=11, init= 'k-means++', max_iter=100, n_init=1 ,verbose=3)\n",
    "model.fit(vectorized) #add sparse matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inertia = []\n",
    "for i in range(2, 13):\n",
    "    km = KMeans(n_clusters = i)\n",
    "    km.fit(vectorized)\n",
    "    inertia.append(km.inertia_)\n",
    "    print (km.inertia_)\n",
    "plt.plot(inertia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "model = KMeans (n_clusters=9, init= 'k-means++', max_iter=100, n_init=1, verbose=3)\n",
    "model.fit(vectorized) #add sparse matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(9):\n",
    "   print \"Cluster %d:\" % i,\n",
    "   for ind in order_centroids[i, :10]:\n",
    "       print ' %s' % terms[ind],\n",
    "   print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from pattern.en import tag\n",
    "import nltk\n",
    "\n",
    "n_topics = 11\n",
    "n_top_words = 7\n",
    "\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()\n",
    "\n",
    "# Create custom tokenizer function that tags part of speech, takes only nouns, stems, and lemmatizes words\n",
    "def noun_tokenize(text):\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "    stemmer = nltk.stem.porter.PorterStemmer()\n",
    "    tokens = []\n",
    "    for item in [token for token in nltk.tokenize.word_tokenize(text) if token not in stopwords]:\n",
    "        word = stemmer.stem_word(item.lower())\n",
    "        word = lemmatizer.lemmatize(word)\n",
    "        tokens.append(word)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "\n",
    "# Load the 20 newsgroups dataset and vectorize it. We use a few heuristics\n",
    "# to filter out useless terms early on: the posts are stripped of headers,\n",
    "# footers and quoted replies, and common English words, words occurring in\n",
    "# only one document or in at least 95% of the documents are removed.\n",
    "\n",
    "import nltk.stem\n",
    "\n",
    "english_stemmer = nltk.stem.SnowballStemmer('english')\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords += ['.', ',', '(', ')', \"'\", '\"', 'ca', 'customer', 'need', 'products', 'would', 'like', 'de', 'sure',\n",
    "             'nothing', 'cost', 'us', 'use', 'get', 'make', 'needs', 'need', 'customer','customers',\n",
    "              'would', 'get', 'like', '30', 'also', 'many', 'day'\n",
    "             '30', '1000', '10', '06', '100', '1000', '1000s', '11', '12', '13','14', '15', '18', '19', '1sr', '200',\n",
    "             '2005', '2009', '2011', '2012', '20126', '2014', '2015', 'vs', 'you', 'we', 'know', 'even', 'see', 'zuk', \n",
    "              'fen' , 'gartner', 'rules', 'cas', 'year', 'nothing', 'look', 'sure', 'solutions', 'better', 'sure' ,\n",
    "              'line', 'one','clear', 'products', 'product', 'tool', '.', ',', '(', ')', \"'\", '\"', ':', ';', '?', '!', \n",
    "              '\"', \"'\", '%', '~', '/', '•', '’', '-', '_', '|', '@', ':', '[', ']']\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(TfidfVectorizer, self).build_analyzer()\n",
    "        return lambda doc: (english_stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "vectorizer = StemmedTfidfVectorizer(min_df=10, max_df=0.5, ngram_range=(1, 3),\n",
    "                                    stop_words=stopwords, decode_error='ignore'\n",
    "                                    )\n",
    "vectorized = vectorizer.fit_transform(df.ltrcomment)\n",
    "\n",
    "lda = LatentDirichletAllocation(n_topics=n_topics, max_iter=60,\n",
    "                                learning_method='online', learning_offset=50.,\n",
    "                                random_state=888)\n",
    "t0 = time()\n",
    "lda.fit(vectorized)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topics=pd.DataFrame(lda.transform(vectorized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_new1=df.join(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_new1=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fy=pd.get_dummies(df_new1['fiscalyear'])\n",
    "geo=pd.get_dummies(df_new1['geo'])\n",
    "role=pd.get_dummies(df_new1['role2'])\n",
    "quarter=pd.get_dummies(df_new1['quarter'])\n",
    "segment=pd.get_dummies(df_new1['segment'])\n",
    "df1=pd.concat([fy, geo, role, quarter, segment, df_new1], axis=1)\n",
    "df1=pd.concat([fy, role, quarter, segment, df_new1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1['ltr_comment_theme1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rename_theme=({'Product Quality': 'Product_Quality', 'Product_Quality': 'Product_Quality', \n",
    "               'Account_Team_Relationship': 'Account_Team_Relationship',\n",
    "               'Contracts': 'Contracts','Product Mentions': 'Product Mentions',\n",
    "               'Contracts_Negotiations': 'Contracts', 'Product_Scope': 'Product Scope',\n",
    "            'Account Mgt': 'Account_Team_Relationship','Account Management and Agent Support': 'Support',\n",
    "           'Support': 'Support','Product Scope': 'Product Scope','Brand': 'Brand','Documentation':'Product_Usability',\n",
    "           'Issue Resolution': \"Support\",'Partners': \"Brand\",'Unable to recommend': \"Unable to recommend\",\n",
    "            'Account_Team':'Account_Team_Relationship', 'Implementations/Upgrades': 'Implementations/Upgrades',\n",
    "               'Implementations_Upgrades': 'Implementations/Upgrades',\n",
    "            'CA Services': 'Services','Product Usability': 'Product_Usability',\n",
    "               'Product_Usability': 'Product_Usability',\n",
    "               'Self_service/KnowledgeBase/Website Topic': 'Self_service/KnowledgeBase/Website'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1['theme1']=df1['ltr_comment_theme1'].map(rename_theme)\n",
    "df1['theme2']=df1['ltr_comment_theme2'].map(rename_theme)\n",
    "df1['theme3']=df1['ltr_comment_theme3'].map(rename_theme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1['ltr_comment_theme3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1['theme3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names=['Support', 'Account_Team_Relationship', 'Contracts', 'Product Scope', 'Product_Quality', 'Services', \n",
    "      'Brand', 'Implementations/Upgrades', 'Product_Usability', 'Documentation', 'Partners',\n",
    "       'Self_service/KnowledgeBase/Website', 'Unable to recommend']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in names:\n",
    "    for column in df1:\n",
    "        df1[i]=df1[i] = np.where((df1.theme1 ==i) | (df1.theme2 == i) | (df1.theme3==i), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in names:\n",
    "    for column in df1:\n",
    "         test=df1[i].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1['Support'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1['Account_Team_Relationship'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1['Contracts'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1['Product Scope'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1['Services'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1['Brand'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1['Implementations/Upgrades'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1['Product_Usability'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1['Documentation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1['Partners'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1['Unable to recommend'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rename_theme=({'Product Quality': 'Product_Quality', 'Product_Quality': 'Product_Quality', \n",
    "               'Account_Team_Relationship': 'Account_Team_Relationship',\n",
    "               'Contracts': 'Contracts','Product Mentions': 'Product_Quality',\n",
    "               'Contracts_Negotiations': 'Contracts', 'Product_Scope': 'Product_Quality',\n",
    "            'Account Mgt': 'Account_Team_Relationship','Account Management and Agent Support': 'Support',\n",
    "           'Support': 'Support','Product Scope': 'Product_Quality','Brand': 'Brand','Documentation':'Product_Quality',\n",
    "           'Issue Resolution': \"Support\",'Partners': \"Brand\",'Unable to recommend': \"Unable to recommend\",\n",
    "            'Account_Team':'Account_Team_Relationship', 'Implementations/Upgrades': 'Implementations/Upgrades',\n",
    "               'Implementations_Upgrades': 'Implementations/Upgrades',\n",
    "            'CA Services': 'Services','Product Usability': 'Product_Quality',\n",
    "               'Product_Usability': 'Product_Quality',\n",
    "               'Self_service/KnowledgeBase/Website Topic': 'Support'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1['theme1']=df1['ltr_comment_theme1'].map(rename_theme)\n",
    "df1['theme2']=df1['ltr_comment_theme2'].map(rename_theme)\n",
    "df1['theme3']=df1['ltr_comment_theme3'].map(rename_theme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1['theme1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_data = df1.drop(['email', 'geo', 'segment', 'role2','ltrcomment', 'fiscalyear', 'FY14', 'FY15', 'FY16', 'quarter'\n",
    "                    , 'ltr_comment_theme1', 'ltr_comment_theme2', 'ltr_comment_theme3', 'theme1', 'theme2', \n",
    "                    'theme3', 'Unable to recommend', 'Partners', 'Documentation', \n",
    "                     'Self_service/KnowledgeBase/Website'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.cross_validation import train_test_split\n",
    "# X=new_data.iloc[:,0:53]\n",
    "# y=new_data.iloc[:,54]\n",
    "# # create 80%-20% train-test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# est=LogisticRegression()\n",
    "# est.fit(X_train, y_train)\n",
    "# pred = est.predict(X_test)\n",
    "# accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scores = [accuracy_score, precision_score, recall_score]\n",
    "# models = [LogisticRegression(), SVC(probability = True), GaussianNB(), DecisionTreeClassifier(max_depth = 4), \n",
    "#           RandomForestClassifier()]\n",
    "# def get_metrics(features, outcome, test=0.2):\n",
    "    \n",
    "#     train_X, test_X, train_y, test_y = train_test_split(features, outcome, test_size = test, random_state=444)\n",
    "\n",
    "    \n",
    "#     # create empty lists\n",
    "#     LogisticReg = []\n",
    "#     SVMC = []\n",
    "#     GaussNB = []\n",
    "#     DecisionTree = []\n",
    "#     RandomForest = []\n",
    "#     kNN9 = []\n",
    "#     ExtraTrees = []\n",
    "    \n",
    "#     # list of lists\n",
    "#     lists = [LogisticReg, SVMC, GaussNB, DecisionTree, RandomForest]\n",
    "    \n",
    "#     # populate lists with scores of each scoring method\n",
    "#     for i, model in enumerate(models):\n",
    "#         for score in scores:\n",
    "#             est = model\n",
    "#             est.fit(train_X, train_y)\n",
    "#             pred = est.predict(test_X)\n",
    "#             lists[i].append(score(test_y, pred))\n",
    "        \n",
    "#     # create a dataframe which aggregates the lists\n",
    "#     scores_df = pd.DataFrame(data = [LogisticReg, SVMC, GaussNB, DecisionTree, RandomForest])\n",
    "#     scores_df.index = [\"LogisticReg\", \"SVMC\", \"GaussNB\", \"DecisionTree\", \"RandomForest\"]\n",
    "#     scores_df.columns = [\"Accuracy\", \"Precision\", \"Recall\"]\n",
    "#     return scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get_metrics(X,y, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification - Naives Bayes/ SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df4=df1[[\n",
    " 'email',\n",
    " 'ltrcomment',\n",
    " 'theme1',\n",
    " 'theme2',\n",
    " 'theme3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df5=pd.melt(df4, id_vars=[ 'email', 'ltrcomment'], value_vars=['theme1', 'theme2', 'theme3'], var_name='theme', \n",
    "            value_name='themes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df5[1:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df5['themes1'] = pd.Categorical.from_array(df5.themes).codes\n",
    "df5=df5.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2=df1[[u'FY14',\n",
    " u'FY15',\n",
    " u'FY16',\n",
    " 'DM/INF',\n",
    " 'END_USER',\n",
    " u'Q1',\n",
    " u'Q2',\n",
    " u'Q3',\n",
    " u'Q4',\n",
    " u'Existing_Enterprise',\n",
    " u'Growth',\n",
    " u'Named',\n",
    " u'New_Enterprise',\n",
    " u'Platinum',\n",
    " 'email',\n",
    " 'geo',\n",
    " 'segment',\n",
    " 'role2',\n",
    " 'ltr',\n",
    " 'acctmgt',\n",
    " 'licensecontract',\n",
    " 'bestpractice',\n",
    " 'implement',\n",
    " 'productqual',\n",
    " 'functionality',\n",
    " 'easeofuse',\n",
    " 'techsupport',\n",
    " 'fiscalyear',\n",
    " 'quarter',\n",
    " 'theme1',\n",
    " 'theme2',\n",
    " 'theme3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3=pd.melt(df2, id_vars=[ 'email','FY16','END_USER', 'Platinum'\n",
    "                         ], value_vars=['theme1', 'theme2', 'theme3'], var_name='theme', value_name='themes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df4=df3.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df4['themes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'Platinum',\n",
    "#  'ltr',\n",
    "#  'acctmgt',\n",
    "#  'licensecontract',\n",
    "#  'bestpractice',\n",
    "#  'implement',\n",
    "#  'productqual',\n",
    "#  'functionality',\n",
    "#  'easeofuse',\n",
    "#  'techsupport'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df4['themes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df4 = df4[(df4.themes != 'Unable to recommend') & (df4.themes != 'Services') & \n",
    "           (df4.themes != 'Implementations/Upgrades') & (df4.themes != 'Product Mentions') \n",
    "          & (df4.themes != 'Product Usability') & (df4.themes != 'Brand') & (df4.themes != 'Contracts')   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df4['themes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4['themes1'] = pd.Categorical.from_array(df4.themes).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X=df4.iloc[:,1:3]\n",
    "y=df4.iloc[:,6]\n",
    "# create 80%-20% train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = [accuracy_score, precision_score, recall_score]\n",
    "models = [SVC(probability = True)]\n",
    "def get_metrics(features, outcome, test=0.2):\n",
    "    \n",
    "    train_X, test_X, train_y, test_y = train_test_split(features, outcome, test_size = test, random_state=444)\n",
    "    \n",
    "    # create empty lists\n",
    "    SVMC = []\n",
    "    RandomForest = []\n",
    "   \n",
    "    # list of lists\n",
    "    lists = [SVMC]    \n",
    "    # populate lists with scores of each scoring method\n",
    "    for i, model in enumerate(models):\n",
    "        for score in scores:\n",
    "            est = model\n",
    "            est.fit(train_X, train_y)\n",
    "            pred = est.predict(test_X)\n",
    "            lists[i].append(score(test_y, pred))\n",
    "        \n",
    "    # create a dataframe which aggregates the lists\n",
    "    scores_df = pd.DataFrame(data = [SVMC])\n",
    "    scores_df.index = [\"SVMC\"]\n",
    "    scores_df.columns = [\"Accuracy\", \"Precision\", \"Recall\"]\n",
    "    return scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = [accuracy_score, precision_score, recall_score]\n",
    "models = [RandomForestClassifier()]\n",
    "def get_metrics1(features, outcome, test=0.2):\n",
    "    \n",
    "    train_X, test_X, train_y, test_y = train_test_split(features, outcome, test_size = test, random_state=444)\n",
    "    \n",
    "    # create empty lists\n",
    "    RandomForest = []\n",
    "   \n",
    "    # list of lists\n",
    "    lists = [RandomForest]    \n",
    "    # populate lists with scores of each scoring method\n",
    "    for i, model in enumerate(models):\n",
    "        for score in scores:\n",
    "            est = model\n",
    "            est.fit(train_X, train_y)\n",
    "            pred = est.predict(test_X)\n",
    "            lists[i].append(score(test_y, pred))\n",
    "        \n",
    "    # create a dataframe which aggregates the lists\n",
    "    scores_df = pd.DataFrame(data = [ RandomForest])\n",
    "    scores_df.index = [\"RandomForest\"]\n",
    "    scores_df.columns = [\"Accuracy\", \"Precision\", \"Recall\"]\n",
    "    return scores_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_metrics(X,y, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_metrics1(X,y, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import grid_search\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=444)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "parameters = {\n",
    "              'max_depth':[5, 7, 9]}\n",
    "\n",
    "clf_grid = grid_search.GridSearchCV(rf, parameters, n_jobs=-1)\n",
    "clf_grid.fit(X_train, y_train)\n",
    "test=clf_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = [accuracy_score, precision_score, recall_score]\n",
    "models = [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)]\n",
    "def get_metrics1(features, outcome, test=0.2):\n",
    "    \n",
    "    train_X, test_X, train_y, test_y = train_test_split(features, outcome, test_size = test, random_state=444)\n",
    "    \n",
    "    # create empty lists\n",
    "    RandomForest = []\n",
    "   \n",
    "    # list of lists\n",
    "    lists = [RandomForest]    \n",
    "    # populate lists with scores of each scoring method\n",
    "    for i, model in enumerate(models):\n",
    "        for score in scores:\n",
    "            est = model\n",
    "            est.fit(train_X, train_y)\n",
    "            pred = est.predict(test_X)\n",
    "            lists[i].append(score(test_y, pred))\n",
    "        \n",
    "    # create a dataframe which aggregates the lists\n",
    "    scores_df = pd.DataFrame(data = [ RandomForest])\n",
    "    scores_df.index = [\"RandomForest\"]\n",
    "    scores_df.columns = [\"Accuracy\", \"Precision\", \"Recall\"]\n",
    "    return scores_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_metrics1(X,y,.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = [accuracy_score, precision_score, recall_score]\n",
    "models = [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)]\n",
    "def get_metrics1(features, outcome, test=0.2):\n",
    "    \n",
    "    train_X, test_X, train_y, test_y = train_test_split(features, outcome, test_size = test, random_state=444)\n",
    "    \n",
    "    # create empty lists\n",
    "    RandomForest = []\n",
    "   \n",
    "    # list of lists\n",
    "    lists = [RandomForest]    \n",
    "    # populate lists with scores of each scoring method\n",
    "    for i, model in enumerate(models):\n",
    "        for score in scores:\n",
    "            est = model\n",
    "            est.fit(train_X, train_y)\n",
    "            pred = est.predict(test_X)\n",
    "            lists[i].append(score(test_y, pred))\n",
    "        \n",
    "    # create a dataframe which aggregates the lists\n",
    "    scores_df = pd.DataFrame(data = [ RandomForest])\n",
    "    scores_df.index = [\"RandomForest\"]\n",
    "    scores_df.columns = [\"Accuracy\", \"Precision\", \"Recall\"]\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test=get_metrics1(X,y,.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(model,x_train,y_train,x_test,y_test,cmap=plt.cm.Blues):\n",
    "    y_pred = model.fit(x_train, y_train).predict(x_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    print(cm_normalized)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(cm_normalized, interpolation='nearest', cmap=cmap)\n",
    "    plt.title('Normalized Confusion Matrix: {}')\n",
    "    plt.colorbar()\n",
    "    plt.xticks([0,1],['Negative diagnosis','Positive Diagnosis'])\n",
    "    plt.yticks([0,1],['Negative diagnosis','Positive Diagnosis'])\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(est,X_train,y_train,X_test,y_test,cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df4['themes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Feature Importance\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "# load the iris datasets\n",
    "# fit an Extra Trees model to the data\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X, y)\n",
    "# display the relative importance of each attribute\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Recursive Feature Elimination\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# load the iris datasets\n",
    "dataset = datasets.load_iris()\n",
    "# create a base classifier used to evaluate a subset of attributes\n",
    "model = LogisticRegression()\n",
    "# create the RFE model and select 3 attributes\n",
    "rfe = RFE(model, 3)\n",
    "rfe = rfe.fit(X,y)\n",
    "# summarize the selection of the attributes\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "model = RandomForestClassifier()\n",
    "parameters = [{\"n_estimators\": [250, 500, 1000]}]\n",
    " \n",
    "# Returns the best configuration for a model using crosvalidation\n",
    "# and grid search\n",
    "def best_config(model, parameters, train_instances, judgements):\n",
    "    clf = GridSearchCV(model, parameters, cv=5,\n",
    "                       scoring=\"accuracy\", verbose=5, n_jobs=4)\n",
    "    clf.fit(train_instances, judgements)\n",
    "    best_estimator = clf.best_estimator_\n",
    "    print('Best hyperparameters: ' + str(clf.best_params_))\n",
    " \n",
    "    return [str(clf.best_params_), clf.best_score_,\n",
    "            best_estimator]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_config(model, parameters, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X=df5.iloc[:,1]\n",
    "y=df5.iloc[:,4]\n",
    "# create 80%-20% train-test split\n",
    "X_train_tdf, X_test_tdf, y_train_tdf, y_test_tdf = train_test_split(X, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk.stem\n",
    "english_stemmer = nltk.stem.SnowballStemmer('english')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "class StemmedTfidfVectorizer(CountVectorizer):\n",
    "\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(CountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: (english_stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "vectorizer = StemmedTfidfVectorizer(min_df=0, max_df=0.5, ngram_range=(1, 5),\n",
    "                                    stop_words=stopwords, decode_error='ignore'\n",
    "                                    )\n",
    "X_train_counts = vectorizer.fit_transform(X_train_tdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naives Bayes Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train_tdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_new_counts = vectorizer.transform(X_test)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),  ('tfidf', TfidfTransformer()),('clf', MultinomialNB()),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_clf = text_clf.fit(X_train_tdf, y_train_tdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "docs_test = X_test\n",
    "predicted = text_clf.predict(X_test_tdf)\n",
    "np.mean(predicted == y_test_tdf)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, predicted))\n",
    "#metrics.confusion_matrix(y_test, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from brew.base import Ensemble\n",
    "from brew.base import EnsembleClassifier\n",
    "from brew.combination import  Combiner\n",
    "\n",
    "# create your Ensemble\n",
    "clfs = your_list_of_classifiers # [clf1, clf2]\n",
    "ens = Ensemble(classifiers = clfs)\n",
    "\n",
    "# create your Combiner\n",
    "# the rules can be 'majority_vote', 'max', 'min', 'mean' or 'median'\n",
    "comb = Combiner(rule='majority_vote')\n",
    "\n",
    "# now create your ensemble classifier\n",
    "ensemble_clf = EnsembleClassifier(ensemble=ens, combiner=comb)\n",
    "ensemble_clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
