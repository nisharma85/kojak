{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import logging\n",
    "from gensim import corpora, models, similarities\n",
    "from pprint import pprint\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "from sklearn import feature_extraction\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.learning_curve import learning_curve\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score,  roc_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import svm, grid_search\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import sklearn\n",
    "import mpld3\n",
    "import lda\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# reload(sys)  \n",
    "# sys.setdefaultencoding('Cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bl=pd.read_csv('data/bl.csv', na_values='DK', encoding='latin-1')\n",
    "fy15q3= pd.read_csv('data/fy15q3.csv', na_values='DK', encoding='latin-1')\n",
    "fy16= pd.read_csv('data/fy16.csv', na_values='DK', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3068"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fy16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fy16['geo']=fy16['geo'].fillna('NaM')\n",
    "fy15q3['Geo']=fy15q3['Geo'].fillna('NaM')\n",
    "bl['Region : Region (Global Area)']=bl['Region : Region (Global Area)'].fillna('NaM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fy16.loc[fy16['translation.to.english.for..ltr.comment'].isnull(),\n",
    "       'comment'] = fy16['ltr.comment']\n",
    "\n",
    "fy15q3.loc[fy15q3['translation_to_1_q_ca_ltrfollowup_reporting_comment'].isnull(),\n",
    "       'comment'] = fy15q3['LTR Comment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fy16_1=fy16[[ 'email', 'geo','segment', 'role2', 'ltr','acct.mgt',\n",
    "      'license.contract', 'best.practice', 'implement', 'product.qual', 'functionality', 'ease.of.use', \n",
    "      'tech.support','fiscalyear', 'quarter', 'ltr.comment','ltr_comment_theme1', 'ltr_comment_theme2',\n",
    "      'ltr_comment_theme3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shani16/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "fy15q3['responsedate'][1061:1064]='NaN'\n",
    "fy15q3['responsedate']=pd.to_datetime(pd.Series(fy15q3['responsedate']), format=\"%m/%d/%y %H:%M\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fy15q3['responseyr'], fy15q3['rmth'] = fy15q3['responsedate'].dt.year, fy15q3['responsedate'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fy15q3['fiscalyear'] = 'NaN'\n",
    "fy15q3.loc[fy15q3['rmth'] > 4, 'fiscalyear'] = \"FY15\"\n",
    "fy15q3['quarter']=\"Q3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fy15q3_1=fy15q3[[ 'Contact Email', 'Geo','Segment', 'Respondent Role', 'LTR', \n",
    "                 'INS - Overall Account Management',\n",
    "      'INS - Licensing and Contract Process', 'INS - Best Practices Advice', 'INS - Product Implementation Process',\n",
    "                 'INS - Overall Quality of Products', 'INS - Overall Functionality of Products', \n",
    "                 'INS - Overall Ease of Use', \n",
    "      'INS - Ability to Get Technical Support','fiscalyear', 'quarter', 'comment','LTR_Comment_Theme1 ',\n",
    "                 'LTR_Comment_Theme2',\n",
    "      'LTR_Comment_Theme3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fy15q3_1.columns=['email', 'geo','segment', 'role2', 'ltr','acct.mgt',\n",
    "      'license.contract', 'best.practice', 'implement', 'product.qual', 'functionality', 'ease.of.use', \n",
    "      'tech.support','fiscalyear', 'quarter', 'ltr.comment','ltr_comment_theme1', 'ltr_comment_theme2',\n",
    "      'ltr_comment_theme3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bl.loc[bl['What can CA Technologies do to improve your likelihood to recommend us? - Translated'].isnull(),\n",
    "       'new'] = bl['What can CA Technologies do to improve your likelihood to recommend us?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bl.loc[bl['What one thing can CA Technologies to improve your likelihod to recommend us? Translated'].isnull(),\n",
    "       'new1'] = bl['What one thing can CA Technologies to improve your likelihod to recommend us?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bl.loc[bl['What can CA Technologies do to improve your likelihood to recommend us? - Translated.1'].isnull(),\n",
    "       'new2'] = bl['What can CA Technologies do to improve your likelihood to recommend us?.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bl['ltr.comment']=pd.concat([bl['new'].dropna(), bl['new1'].dropna(), bl['new2'].dropna() ]).reindex_like(bl)\n",
    "bl['theme1']=pd.concat([bl['LTR_Promoters_Theme1'].dropna(), bl['LTR_Passives_Theme1'].dropna(), bl['LTR_Detractors_Theme1'].dropna() ]).reindex_like(bl)\n",
    "bl['theme2']=pd.concat([bl['LTR_Promoters_Theme2'].dropna(), bl['LTR_Passives_Theme2'].dropna(), bl['LTR_Detractors_Theme2'].dropna() ]).reindex_like(bl)\n",
    "bl['theme3']=pd.concat([bl['LTR_Promoters_Theme3'].dropna(), bl['LTR_Passives_Theme3 : LTR_Passives_Theme3'].dropna(), bl['LTR_Detractors_Theme3'].dropna() ]).reindex_like(bl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# bl.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bl_1=bl[[ 'ContactEmail : ContactEmail', 'Region : Region (Global Area)','AccountType : AccountType',\n",
    "         'Role_New_WP : Role', 'How likely are you to recommend CA Technologies ', \n",
    "        u'Overall Account Management\\xe6\\xe6\\xe6\\xe6\\xe6\\xe6\\xe6\\xe6\\xe6\\xe6\\xe6\\xe6\\xe6\\xe6',\n",
    "      'Licensing and contract process', 'Best-practices advice', 'Product implementation process',\n",
    "                 'Overall quality of products', 'Overall functionality of products', \n",
    "                 'Overall ease of use of CA Technologies products', 'Ability to get technical support from CA Technologies',\n",
    "         'Fiscal Year', 'Quarter', \n",
    "         'ltr.comment','theme1', 'theme2', 'theme3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bl_1.columns=['email', 'geo','segment', 'role2', 'ltr','acct.mgt',\n",
    "      'license.contract', 'best.practice', 'implement', 'product.qual', 'functionality', 'ease.of.use', \n",
    "      'tech.support','fiscalyear', 'quarter', 'ltr.comment','ltr_comment_theme1', 'ltr_comment_theme2',\n",
    "      'ltr_comment_theme3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shani16/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "fy15q3_1['role2'] = fy15q3_1['role2'].map({'End User': 'END_USER', 'Influencer': 'DM/INF', 'Decision Maker': 'DM/INF', 'Recommender': 'END_USER'   })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shani16/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "bl_1['role2'] = bl_1['role2'].map({'END': 'END_USER', 'INF': 'DM/INF', 'DM': 'DM/INF', 'PRO': 'END_USER'   })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FY16    3068\n",
       "Name: fiscalyear, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fy16_1['fiscalyear'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frames= [bl_1, fy15q3_1, fy16_1]\n",
    "df=pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df[pd.notnull(df['ltr.comment'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>geo</th>\n",
       "      <th>segment</th>\n",
       "      <th>role2</th>\n",
       "      <th>ltr</th>\n",
       "      <th>acct.mgt</th>\n",
       "      <th>license.contract</th>\n",
       "      <th>best.practice</th>\n",
       "      <th>implement</th>\n",
       "      <th>product.qual</th>\n",
       "      <th>functionality</th>\n",
       "      <th>ease.of.use</th>\n",
       "      <th>tech.support</th>\n",
       "      <th>fiscalyear</th>\n",
       "      <th>quarter</th>\n",
       "      <th>ltr.comment</th>\n",
       "      <th>ltr_comment_theme1</th>\n",
       "      <th>ltr_comment_theme2</th>\n",
       "      <th>ltr_comment_theme3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alain.z.cote@dgag.ca</td>\n",
       "      <td>NaM</td>\n",
       "      <td>Named</td>\n",
       "      <td>END_USER</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6.913793</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>FY14</td>\n",
       "      <td>Q2</td>\n",
       "      <td>Improve the quality, stability and integration...</td>\n",
       "      <td>Product_Quality</td>\n",
       "      <td>Product_Scope</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>matt.merchant@ge.com</td>\n",
       "      <td>NaM</td>\n",
       "      <td>Platinum</td>\n",
       "      <td>DM/INF</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>7.271079</td>\n",
       "      <td>7.542117</td>\n",
       "      <td>FY14</td>\n",
       "      <td>Q2</td>\n",
       "      <td>ITSM space is best for CA. Still work to be do...</td>\n",
       "      <td>Product_Scope</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chris.schwind@firstdata.com</td>\n",
       "      <td>NaM</td>\n",
       "      <td>Platinum</td>\n",
       "      <td>END_USER</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>6.913793</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>FY14</td>\n",
       "      <td>Q2</td>\n",
       "      <td>Service Assurance, Mainframe tools, Scheduling...</td>\n",
       "      <td>Product_Scope</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dominic.nguyen@ge.com</td>\n",
       "      <td>NaM</td>\n",
       "      <td>Platinum</td>\n",
       "      <td>END_USER</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>6.913793</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>FY14</td>\n",
       "      <td>Q2</td>\n",
       "      <td>Needs to get product more stable and less bugs</td>\n",
       "      <td>Product_Quality</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mz1223@att.com</td>\n",
       "      <td>NaM</td>\n",
       "      <td>Platinum</td>\n",
       "      <td>END_USER</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6.913793</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>FY14</td>\n",
       "      <td>Q2</td>\n",
       "      <td>We primarily use Introscope under the APM suit...</td>\n",
       "      <td>Contracts_Negotiations</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         email  geo   segment     role2  ltr  acct.mgt  \\\n",
       "1         alain.z.cote@dgag.ca  NaM     Named  END_USER    0         9   \n",
       "2         matt.merchant@ge.com  NaM  Platinum    DM/INF    9        10   \n",
       "3  chris.schwind@firstdata.com  NaM  Platinum  END_USER    9        10   \n",
       "4        dominic.nguyen@ge.com  NaM  Platinum  END_USER    3         8   \n",
       "5               mz1223@att.com  NaM  Platinum  END_USER    7         8   \n",
       "\n",
       "   license.contract  best.practice  implement  product.qual  functionality  \\\n",
       "1          6.913793              4          2             0              6   \n",
       "2          8.000000              9         10             9              9   \n",
       "3          6.913793              9          7             8              8   \n",
       "4          6.913793              7          3             2              4   \n",
       "5          6.913793             10         10             9             10   \n",
       "\n",
       "   ease.of.use  tech.support fiscalyear quarter  \\\n",
       "1     0.000000      0.000000       FY14      Q2   \n",
       "2     7.271079      7.542117       FY14      Q2   \n",
       "3     8.000000      8.000000       FY14      Q2   \n",
       "4     2.000000      3.000000       FY14      Q2   \n",
       "5     8.000000      2.000000       FY14      Q2   \n",
       "\n",
       "                                         ltr.comment      ltr_comment_theme1  \\\n",
       "1  Improve the quality, stability and integration...         Product_Quality   \n",
       "2  ITSM space is best for CA. Still work to be do...           Product_Scope   \n",
       "3  Service Assurance, Mainframe tools, Scheduling...           Product_Scope   \n",
       "4     Needs to get product more stable and less bugs         Product_Quality   \n",
       "5  We primarily use Introscope under the APM suit...  Contracts_Negotiations   \n",
       "\n",
       "  ltr_comment_theme2 ltr_comment_theme3  \n",
       "1      Product_Scope                NaN  \n",
       "2                NaN                NaN  \n",
       "3                NaN                NaN  \n",
       "4                NaN                NaN  \n",
       "5                NaN                NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.913793     2817\n",
       "8.000000      470\n",
       "7.000000      382\n",
       "9.000000      313\n",
       "6.000000      235\n",
       "10.000000     181\n",
       "5.000000      178\n",
       "4.000000       82\n",
       "3.000000       66\n",
       "2.000000       56\n",
       "1.000000       36\n",
       "0.000000       31\n",
       "Name: license.contract, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['license.contract'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['ltr.comment']=df['ltr.comment'].str.replace(r'\\?', '')\n",
    "df['ltr.comment']=df['ltr.comment'].str.replace(r'\\r', '')\n",
    "df['ltr.comment']=df['ltr.comment'].str.replace(r'\\#NAME', '')\n",
    "df['ltr.comment']=df['ltr.comment'].str.replace(r'n/a', '')\n",
    "df['ltr.comment']=df['ltr.comment'].str.replace(r'na', '')\n",
    "df['ltr.comment']=df['ltr.comment'].str.replace(r'-', '')\n",
    "df['ltr.comment']=df['ltr.comment'].str.replace(r'.', '')\n",
    "df['ltr.comment']=df['ltr.comment'].str.replace(r'___', '')\n",
    "df['ltr.comment']=df['ltr.comment'].str.replace(r'_', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FY16    2418\n",
       "FY15    1374\n",
       "FY14    1051\n",
       "Name: fiscalyear, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['fiscalyear'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['email',\n",
       " 'geo',\n",
       " 'segment',\n",
       " 'role2',\n",
       " 'ltr',\n",
       " 'acct.mgt',\n",
       " 'license.contract',\n",
       " 'best.practice',\n",
       " 'implement',\n",
       " 'product.qual',\n",
       " 'functionality',\n",
       " 'ease.of.use',\n",
       " 'tech.support',\n",
       " 'fiscalyear',\n",
       " 'quarter',\n",
       " 'ltr.comment',\n",
       " 'ltr_comment_theme1',\n",
       " 'ltr_comment_theme2',\n",
       " 'ltr_comment_theme3']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns=[ 'email',\n",
    " 'geo',\n",
    " 'segment',\n",
    " 'role2',\n",
    " 'ltr',\n",
    " 'acctmgt',\n",
    " 'licensecontract',\n",
    " 'bestpractice',\n",
    " 'implement',\n",
    " 'productqual',\n",
    " 'functionality',\n",
    " 'easeofuse',\n",
    " 'techsupport',\n",
    " 'fiscalyear',\n",
    " 'quarter',\n",
    " 'ltrcomment',\n",
    " 'ltr_comment_theme1',\n",
    " 'ltr_comment_theme2',\n",
    " 'ltr_comment_theme3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords += ['.', ',', '(', ')', \"'\", '\"', 'ca', 'customer', 'need', 'products', 'would', 'like', 'de', 'sure',\n",
    "             'nothing', 'cost', 'us', 'use', 'get', 'make', 'needs', 'need', 'customer','customers',\n",
    "              'would', 'get', 'like', '30', 'also', 'many', 'day'\n",
    "             '30', '1000', '10', '06', '100', '1000', '1000s', '11', '12', '13','14', '15', '18', '19', '1sr', '200',\n",
    "             '2005', '2009', '2011', '2012', '20126', '2014', '2015', 'vs', 'you', 'we', 'know', 'even', 'see', 'zuk', \n",
    "              'fen' , 'gartner', 'rules', 'cas', 'year', 'nothing', 'look', 'sure', 'solutions', 'better', 'sure' ,\n",
    "              'line', 'one','clear', 'products', 'product', 'tool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_clusters = 50  # sp.unique(labels).shape[0]\n",
    "\n",
    "import nltk.stem\n",
    "english_stemmer = nltk.stem.SnowballStemmer('english')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(TfidfVectorizer, self).build_analyzer()\n",
    "        return lambda doc: (english_stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "vectorizer = StemmedTfidfVectorizer(min_df=10, max_df=0.5, ngram_range=(1, 5),\n",
    "                                    stop_words=stopwords, decode_error='ignore'\n",
    "                                    )\n",
    "vectorized = vectorizer.fit_transform(df.ltrcomment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>accept</th>\n",
       "      <th>access</th>\n",
       "      <th>access mag</th>\n",
       "      <th>account</th>\n",
       "      <th>account mag</th>\n",
       "      <th>account rep</th>\n",
       "      <th>account team</th>\n",
       "      <th>accur</th>\n",
       "      <th>...</th>\n",
       "      <th>work</th>\n",
       "      <th>work wel</th>\n",
       "      <th>workflow</th>\n",
       "      <th>workload</th>\n",
       "      <th>workload autom</th>\n",
       "      <th>world</th>\n",
       "      <th>year</th>\n",
       "      <th>yet</th>\n",
       "      <th>zu</th>\n",
       "      <th>ørea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 994 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abil  abl  accept  access  access mag  account  account mag  account rep  \\\n",
       "0     0    0       0       0           0        0            0            0   \n",
       "\n",
       "   account team  accur  ...   work  work wel  workflow  workload  \\\n",
       "0             0      0  ...      0         0         0         0   \n",
       "\n",
       "   workload autom  world  year  yet  zu  ørea  \n",
       "0               0      0     0    0   0     0  \n",
       "\n",
       "[1 rows x 994 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature= vectorized.toarray()\n",
    "feature_df = pd.DataFrame(feature, columns=vectorizer.get_feature_names())\n",
    "feature_df[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shani16/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>support</td>\n",
       "      <td>213.316302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>servic</td>\n",
       "      <td>150.190064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>improv</td>\n",
       "      <td>124.487970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>price</td>\n",
       "      <td>90.300350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>work</td>\n",
       "      <td>84.604365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>provid</td>\n",
       "      <td>82.341187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>magement</td>\n",
       "      <td>77.312356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>softwar</td>\n",
       "      <td>75.974886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>integr</td>\n",
       "      <td>74.493733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>technolog</td>\n",
       "      <td>74.320558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word        freq\n",
       "858    support  213.316302\n",
       "774     servic  150.190064\n",
       "404     improv  124.487970\n",
       "654      price   90.300350\n",
       "984       work   84.604365\n",
       "682     provid   82.341187\n",
       "505   magement   77.312356\n",
       "811    softwar   75.974886\n",
       "427     integr   74.493733\n",
       "889  technolog   74.320558"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequency = feature_df.sum().reset_index()\n",
    "word_frequency.columns=['word', 'freq']\n",
    "\n",
    "word_frequency=word_frequency.sort(columns='freq', ascending= False)\n",
    "word_frequency[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "model = KMeans (n_clusters=30, init= 'k-means++', max_iter=100, n_init=1, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration  0, inertia 8110.194\n",
      "Iteration  1, inertia 4298.179\n",
      "Iteration  2, inertia 4258.038\n",
      "Iteration  3, inertia 4244.658\n",
      "Iteration  4, inertia 4239.233\n",
      "Iteration  5, inertia 4237.179\n",
      "Iteration  6, inertia 4236.040\n",
      "Iteration  7, inertia 4234.901\n",
      "Iteration  8, inertia 4233.792\n",
      "Iteration  9, inertia 4233.206\n",
      "Iteration 10, inertia 4232.973\n",
      "Iteration 11, inertia 4232.859\n",
      "Iteration 12, inertia 4232.842\n",
      "Iteration 13, inertia 4232.825\n",
      "Iteration 14, inertia 4232.813\n",
      "Iteration 15, inertia 4232.807\n",
      "Iteration 16, inertia 4232.803\n",
      "Converged at iteration 16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=11, n_init=1,\n",
       "    n_jobs=1, precompute_distances='auto', random_state=None, tol=0.0001,\n",
       "    verbose=3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KMeans (n_clusters=11, init= 'k-means++', max_iter=100, n_init=1 ,verbose=3)\n",
    "model.fit(vectorized) #add sparse matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4457.54771327\n",
      "4415.39176993\n",
      "4396.1321357\n",
      "4351.49775249\n",
      "4328.88419519\n",
      "4306.65205987\n",
      "4290.81835654\n",
      "4290.25633811\n",
      "4269.74825483\n",
      "4224.03284738\n",
      "4213.76944598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x115b888d0>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nARGRBFMIiIgkmEJARCTB/h++7fjVrsHC3QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116650910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inertia = []\n",
    "for i in range(2, 13):\n",
    "    km = KMeans(n_clusters = i)\n",
    "    km.fit(vectorized)\n",
    "    inertia.append(km.inertia_)\n",
    "    print km.inertia_\n",
    "plt.plot(inertia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration  0, inertia 4543.046\n",
      "Iteration  1, inertia 4451.738\n",
      "Iteration  2, inertia 4426.278\n",
      "Iteration  3, inertia 4403.793\n",
      "Iteration  4, inertia 4394.044\n",
      "Iteration  5, inertia 4389.431\n",
      "Iteration  6, inertia 4385.327\n",
      "Iteration  7, inertia 4383.541\n",
      "Iteration  8, inertia 4382.284\n",
      "Iteration  9, inertia 4381.760\n",
      "Iteration 10, inertia 4381.619\n",
      "Iteration 11, inertia 4381.574\n",
      "Iteration 12, inertia 4381.559\n",
      "Iteration 13, inertia 4381.550\n",
      "Converged at iteration 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=9, n_init=1,\n",
       "    n_jobs=1, precompute_distances='auto', random_state=None, tol=0.0001,\n",
       "    verbose=3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "model = KMeans (n_clusters=9, init= 'k-means++', max_iter=100, n_init=1, verbose=3)\n",
    "model.fit(vectorized) #add sparse matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0:  team  support  account  support team  account team  sale  work  issu  sales team  respons\n",
      "Cluster 1:  price  reach  easili  cycl  amount  done  point  licens  perform  tool\n",
      "Cluster 2:  solut  re  workflow  idm  share  compon  limit  multipl  believ  singl\n",
      "Cluster 3:  magement  account mag  servic  ident  access mag  access  account  secur  project  service mag\n",
      "Cluster 4:  improv  support  qualiti  improve support  improve qu  servic  time  document  integr  issu\n",
      "Cluster 5:  success  meet  requir  implement  monitor  propos  new  resourc  ensur  provid\n",
      "Cluster 6:  incorpor  rapid  suggest  main  roadmap  client  ørea  fincial  fil  file\n",
      "Cluster 7:  support  servic  provid  work  technolog  softwar  integr  tool  issu  good\n",
      "Cluster 8:  price  lower  lower pric  flexibl  competit  licens  pricing model  competitive pr  model  transpar\n"
     ]
    }
   ],
   "source": [
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(9):\n",
    "   print \"Cluster %d:\" % i,\n",
    "   for ind in order_centroids[i, :10]:\n",
    "       print ' %s' % terms[ind],\n",
    "   print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 37.328s.\n",
      "\n",
      "Topics in LDA model:\n",
      "Topic #0:\n",
      "mainfram la en tool producto el los\n",
      "Topic #1:\n",
      "integr easier suit enterpris maggior quicker autom\n",
      "Topic #2:\n",
      "support servic qualiti improv autom virtual good\n",
      "Topic #3:\n",
      "produto desk service desk da com client que\n",
      "Topic #4:\n",
      "ppm clariti specif monitoreo clarity ppm roadmap usabl\n",
      "Topic #5:\n",
      "support work provid technolog servic improv issu\n",
      "Topic #6:\n",
      "monitor secur magement licens cost applic reduc\n",
      "Topic #7:\n",
      "document respons des eas stabil time les\n",
      "Topic #8:\n",
      "schedul di assur prodotti matter service assur dei\n",
      "Topic #9:\n",
      "apm und der die produkt im von\n",
      "Topic #10:\n",
      "price flexibl lower competit transpar contract lower pric\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from pattern.en import tag\n",
    "import nltk\n",
    "\n",
    "n_topics = 11\n",
    "n_top_words = 7\n",
    "\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()\n",
    "\n",
    "# Create custom tokenizer function that tags part of speech, takes only nouns, stems, and lemmatizes words\n",
    "def noun_tokenize(text):\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "    stemmer = nltk.stem.porter.PorterStemmer()\n",
    "    tokens = []\n",
    "    for item in [token for token in nltk.tokenize.word_tokenize(text) if token not in stopwords]:\n",
    "        word = stemmer.stem_word(item.lower())\n",
    "        word = lemmatizer.lemmatize(word)\n",
    "        tokens.append(word)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "\n",
    "# Load the 20 newsgroups dataset and vectorize it. We use a few heuristics\n",
    "# to filter out useless terms early on: the posts are stripped of headers,\n",
    "# footers and quoted replies, and common English words, words occurring in\n",
    "# only one document or in at least 95% of the documents are removed.\n",
    "\n",
    "import nltk.stem\n",
    "\n",
    "english_stemmer = nltk.stem.SnowballStemmer('english')\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords += ['.', ',', '(', ')', \"'\", '\"', 'ca', 'customer', 'need', 'products', 'would', 'like', 'de', 'sure',\n",
    "             'nothing', 'cost', 'us', 'use', 'get', 'make', 'needs', 'need', 'customer','customers',\n",
    "              'would', 'get', 'like', '30', 'also', 'many', 'day'\n",
    "             '30', '1000', '10', '06', '100', '1000', '1000s', '11', '12', '13','14', '15', '18', '19', '1sr', '200',\n",
    "             '2005', '2009', '2011', '2012', '20126', '2014', '2015', 'vs', 'you', 'we', 'know', 'even', 'see', 'zuk', \n",
    "              'fen' , 'gartner', 'rules', 'cas', 'year', 'nothing', 'look', 'sure', 'solutions', 'better', 'sure' ,\n",
    "              'line', 'one','clear', 'products', 'product', 'tool', '.', ',', '(', ')', \"'\", '\"', ':', ';', '?', '!', \n",
    "              '\"', \"'\", '%', '~', '/', '•', '’', '-', '_', '|', '@', ':', '[', ']']\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(TfidfVectorizer, self).build_analyzer()\n",
    "        return lambda doc: (english_stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "vectorizer = StemmedTfidfVectorizer(min_df=10, max_df=0.5, ngram_range=(1, 3),\n",
    "                                    stop_words=stopwords, decode_error='ignore'\n",
    "                                    )\n",
    "vectorized = vectorizer.fit_transform(df.ltrcomment)\n",
    "\n",
    "lda = LatentDirichletAllocation(n_topics=n_topics, max_iter=60,\n",
    "                                learning_method='online', learning_offset=50.,\n",
    "                                random_state=888)\n",
    "t0 = time()\n",
    "lda.fit(vectorized)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topics=pd.DataFrame(lda.transform(vectorized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_new1=df.join(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_new1=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fy=pd.get_dummies(df_new1['fiscalyear'])\n",
    "geo=pd.get_dummies(df_new1['geo'])\n",
    "role=pd.get_dummies(df_new1['role2'])\n",
    "quarter=pd.get_dummies(df_new1['quarter'])\n",
    "segment=pd.get_dummies(df_new1['segment'])\n",
    "df1=pd.concat([fy, geo, role, quarter, segment, df_new1], axis=1)\n",
    "df1=pd.concat([fy, role, quarter, segment, df_new1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'FY14',\n",
       " u'FY15',\n",
       " u'FY16',\n",
       " 'DM/INF',\n",
       " 'END_USER',\n",
       " u'Q1',\n",
       " u'Q2',\n",
       " u'Q3',\n",
       " u'Q4',\n",
       " u'Existing_Enterprise',\n",
       " u'Growth',\n",
       " u'Named',\n",
       " u'New_Enterprise',\n",
       " u'Platinum',\n",
       " 'email',\n",
       " 'geo',\n",
       " 'segment',\n",
       " 'role2',\n",
       " 'ltr',\n",
       " 'acctmgt',\n",
       " 'licensecontract',\n",
       " 'bestpractice',\n",
       " 'implement',\n",
       " 'productqual',\n",
       " 'functionality',\n",
       " 'easeofuse',\n",
       " 'techsupport',\n",
       " 'fiscalyear',\n",
       " 'quarter',\n",
       " 'ltrcomment',\n",
       " 'ltr_comment_theme1',\n",
       " 'ltr_comment_theme2',\n",
       " 'ltr_comment_theme3']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product_Quality                             534\n",
       "Support                                     509\n",
       "Account Mgt                                 413\n",
       "Account_Team_Relationship                   412\n",
       "Product_Scope                               337\n",
       "Account Management and Agent Support        281\n",
       "Contracts_Negotiations                      232\n",
       "Contracts                                   206\n",
       "Product Mentions                            205\n",
       "Product_Usability                           164\n",
       "Product Scope                               163\n",
       "Product Quality                             107\n",
       "Implementations_Upgrades                     86\n",
       "CA Services                                  75\n",
       "Services                                     74\n",
       "Brand                                        73\n",
       "Implementations/Upgrades                     71\n",
       "Product Usability                            58\n",
       "Documentation                                28\n",
       "Issue Resolution                             22\n",
       "Partners                                     10\n",
       "Unable to recommend                           3\n",
       "Self_service/KnowledgeBase/Website            3\n",
       "Self_service/KnowledgeBase/Website Topic      3\n",
       "Account_Team                                  1\n",
       "Name: ltr_comment_theme1, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['ltr_comment_theme1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rename_theme=({'Product Quality': 'Product_Quality', 'Product_Quality': 'Product_Quality', \n",
    "               'Account_Team_Relationship': 'Account_Team_Relationship',\n",
    "               'Contracts': 'Contracts','Product Mentions': 'Product Mentions',\n",
    "               'Contracts_Negotiations': 'Contracts', 'Product_Scope': 'Product Scope',\n",
    "            'Account Mgt': 'Account_Team_Relationship','Account Management and Agent Support': 'Support',\n",
    "           'Support': 'Support','Product Scope': 'Product Scope','Brand': 'Brand','Documentation':'Product_Usability',\n",
    "           'Issue Resolution': \"Support\",'Partners': \"Brand\",'Unable to recommend': \"Unable to recommend\",\n",
    "            'Account_Team':'Account_Team_Relationship', 'Implementations/Upgrades': 'Implementations/Upgrades',\n",
    "               'Implementations_Upgrades': 'Implementations/Upgrades',\n",
    "            'CA Services': 'Services','Product Usability': 'Product_Usability',\n",
    "               'Product_Usability': 'Product_Usability',\n",
    "               'Self_service/KnowledgeBase/Website Topic': 'Self_service/KnowledgeBase/Website'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1['theme1']=df1['ltr_comment_theme1'].map(rename_theme)\n",
    "df1['theme2']=df1['ltr_comment_theme2'].map(rename_theme)\n",
    "df1['theme3']=df1['ltr_comment_theme3'].map(rename_theme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Support                                     118\n",
       "Product Scope                                68\n",
       "Product Mentions                             56\n",
       "Product Usability                            44\n",
       "Account Mgt                                  28\n",
       "Implementations/Upgrades                     22\n",
       "Contracts                                    20\n",
       "CA Services                                  19\n",
       "Issue Resolution                             18\n",
       "Product Quality                              17\n",
       "Account_Team_Relationship                    16\n",
       "Brand                                        12\n",
       "Account Management and Agent Support          9\n",
       "Product_Scope                                 9\n",
       "Product_Quality                               8\n",
       "Self_service/KnowledgeBase/Website            7\n",
       "Self_service/KnowledgeBase/Website Topic      7\n",
       "Implementations_Upgrades                      6\n",
       "Services                                      5\n",
       "Product_Usability                             2\n",
       "Contracts_Negotiations                        1\n",
       "Theme3                                        1\n",
       "Name: ltr_comment_theme3, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['ltr_comment_theme3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Support                               145\n",
       "Product Scope                          77\n",
       "Product Mentions                       56\n",
       "Product_Usability                      46\n",
       "Account_Team_Relationship              44\n",
       "Implementations/Upgrades               28\n",
       "Product_Quality                        25\n",
       "Contracts                              21\n",
       "Services                               19\n",
       "Brand                                  12\n",
       "Self_service/KnowledgeBase/Website      7\n",
       "Name: theme3, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['theme3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names=['Support', 'Account_Team_Relationship', 'Contracts', 'Product Scope', 'Product_Quality', 'Services', \n",
    "      'Brand', 'Implementations/Upgrades', 'Product_Usability', 'Documentation', 'Partners',\n",
    "       'Self_service/KnowledgeBase/Website', 'Unable to recommend']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in names:\n",
    "    for column in df1:\n",
    "        df1[i]=df1[i] = np.where((df1.theme1 ==i) | (df1.theme2 == i) | (df1.theme3==i), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in names:\n",
    "    for column in df1:\n",
    "         test=df1[i].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3806\n",
       "1    1041\n",
       "Name: Support, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Support'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3920\n",
       "1     927\n",
       "Name: Account_Team_Relationship, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Account_Team_Relationship'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4330\n",
       "1     517\n",
       "Name: Contracts, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Contracts'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4101\n",
       "1     746\n",
       "Name: Product Scope, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Product Scope'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4725\n",
       "1     122\n",
       "Name: Services, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Services'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4720\n",
       "1     127\n",
       "Name: Brand, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Brand'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4605\n",
       "1     242\n",
       "Name: Implementations/Upgrades, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Implementations/Upgrades'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4460\n",
       "1     387\n",
       "Name: Product_Usability, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Product_Usability'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4847\n",
       "Name: Documentation, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Documentation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4847\n",
       "Name: Partners, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Partners'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4844\n",
       "1       3\n",
       "Name: Unable to recommend, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Unable to recommend'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rename_theme=({'Product Quality': 'Product_Quality', 'Product_Quality': 'Product_Quality', \n",
    "               'Account_Team_Relationship': 'Account_Team_Relationship',\n",
    "               'Contracts': 'Contracts','Product Mentions': 'Product_Quality',\n",
    "               'Contracts_Negotiations': 'Contracts', 'Product_Scope': 'Product_Quality',\n",
    "            'Account Mgt': 'Account_Team_Relationship','Account Management and Agent Support': 'Support',\n",
    "           'Support': 'Support','Product Scope': 'Product_Quality','Brand': 'Brand','Documentation':'Product_Quality',\n",
    "           'Issue Resolution': \"Support\",'Partners': \"Brand\",'Unable to recommend': \"Unable to recommend\",\n",
    "            'Account_Team':'Account_Team_Relationship', 'Implementations/Upgrades': 'Implementations/Upgrades',\n",
    "               'Implementations_Upgrades': 'Implementations/Upgrades',\n",
    "            'CA Services': 'Services','Product Usability': 'Product_Quality',\n",
    "               'Product_Usability': 'Product_Quality',\n",
    "               'Self_service/KnowledgeBase/Website Topic': 'Support'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1['theme1']=df1['ltr_comment_theme1'].map(rename_theme)\n",
    "df1['theme2']=df1['ltr_comment_theme2'].map(rename_theme)\n",
    "df1['theme3']=df1['ltr_comment_theme3'].map(rename_theme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product_Quality              1596\n",
       "Account_Team_Relationship     826\n",
       "Support                       815\n",
       "Contracts                     438\n",
       "Implementations/Upgrades      157\n",
       "Brand                          83\n",
       "Services                       75\n",
       "Unable to recommend             3\n",
       "Name: theme1, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['theme1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'FY14',\n",
       " u'FY15',\n",
       " u'FY16',\n",
       " 'DM/INF',\n",
       " 'END_USER',\n",
       " u'Q1',\n",
       " u'Q2',\n",
       " u'Q3',\n",
       " u'Q4',\n",
       " u'Existing_Enterprise',\n",
       " u'Growth',\n",
       " u'Named',\n",
       " u'New_Enterprise',\n",
       " u'Platinum',\n",
       " 'email',\n",
       " 'geo',\n",
       " 'segment',\n",
       " 'role2',\n",
       " 'ltr',\n",
       " 'acctmgt',\n",
       " 'licensecontract',\n",
       " 'bestpractice',\n",
       " 'implement',\n",
       " 'productqual',\n",
       " 'functionality',\n",
       " 'easeofuse',\n",
       " 'techsupport',\n",
       " 'fiscalyear',\n",
       " 'quarter',\n",
       " 'ltrcomment',\n",
       " 'ltr_comment_theme1',\n",
       " 'ltr_comment_theme2',\n",
       " 'ltr_comment_theme3',\n",
       " 'theme1',\n",
       " 'theme2',\n",
       " 'theme3',\n",
       " 'Support',\n",
       " 'Account_Team_Relationship',\n",
       " 'Contracts',\n",
       " 'Product Scope',\n",
       " 'Product_Quality',\n",
       " 'Services',\n",
       " 'Brand',\n",
       " 'Implementations/Upgrades',\n",
       " 'Product_Usability',\n",
       " 'Documentation',\n",
       " 'Partners',\n",
       " 'Self_service/KnowledgeBase/Website',\n",
       " 'Unable to recommend']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_data = df1.drop(['email', 'geo', 'segment', 'role2','ltrcomment', 'fiscalyear', 'FY14', 'FY15', 'FY16', 'quarter'\n",
    "                    , 'ltr_comment_theme1', 'ltr_comment_theme2', 'ltr_comment_theme3', 'theme1', 'theme2', \n",
    "                    'theme3', 'Unable to recommend', 'Partners', 'Documentation', \n",
    "                     'Self_service/KnowledgeBase/Website'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DM/INF',\n",
       " 'END_USER',\n",
       " u'Q1',\n",
       " u'Q2',\n",
       " u'Q3',\n",
       " u'Q4',\n",
       " u'Existing_Enterprise',\n",
       " u'Growth',\n",
       " u'Named',\n",
       " u'New_Enterprise',\n",
       " u'Platinum',\n",
       " 'ltr',\n",
       " 'acctmgt',\n",
       " 'licensecontract',\n",
       " 'bestpractice',\n",
       " 'implement',\n",
       " 'productqual',\n",
       " 'functionality',\n",
       " 'easeofuse',\n",
       " 'techsupport',\n",
       " 'Support',\n",
       " 'Account_Team_Relationship',\n",
       " 'Contracts',\n",
       " 'Product Scope',\n",
       " 'Product_Quality',\n",
       " 'Services',\n",
       " 'Brand',\n",
       " 'Implementations/Upgrades',\n",
       " 'Product_Usability']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.cross_validation import train_test_split\n",
    "# X=new_data.iloc[:,0:53]\n",
    "# y=new_data.iloc[:,54]\n",
    "# # create 80%-20% train-test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# est=LogisticRegression()\n",
    "# est.fit(X_train, y_train)\n",
    "# pred = est.predict(X_test)\n",
    "# accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scores = [accuracy_score, precision_score, recall_score]\n",
    "# models = [LogisticRegression(), SVC(probability = True), GaussianNB(), DecisionTreeClassifier(max_depth = 4), \n",
    "#           RandomForestClassifier()]\n",
    "# def get_metrics(features, outcome, test=0.2):\n",
    "    \n",
    "#     train_X, test_X, train_y, test_y = train_test_split(features, outcome, test_size = test, random_state=444)\n",
    "\n",
    "    \n",
    "#     # create empty lists\n",
    "#     LogisticReg = []\n",
    "#     SVMC = []\n",
    "#     GaussNB = []\n",
    "#     DecisionTree = []\n",
    "#     RandomForest = []\n",
    "#     kNN9 = []\n",
    "#     ExtraTrees = []\n",
    "    \n",
    "#     # list of lists\n",
    "#     lists = [LogisticReg, SVMC, GaussNB, DecisionTree, RandomForest]\n",
    "    \n",
    "#     # populate lists with scores of each scoring method\n",
    "#     for i, model in enumerate(models):\n",
    "#         for score in scores:\n",
    "#             est = model\n",
    "#             est.fit(train_X, train_y)\n",
    "#             pred = est.predict(test_X)\n",
    "#             lists[i].append(score(test_y, pred))\n",
    "        \n",
    "#     # create a dataframe which aggregates the lists\n",
    "#     scores_df = pd.DataFrame(data = [LogisticReg, SVMC, GaussNB, DecisionTree, RandomForest])\n",
    "#     scores_df.index = [\"LogisticReg\", \"SVMC\", \"GaussNB\", \"DecisionTree\", \"RandomForest\"]\n",
    "#     scores_df.columns = [\"Accuracy\", \"Precision\", \"Recall\"]\n",
    "#     return scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get_metrics(X,y, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification - Naives Bayes/ SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df4=df1[[\n",
    " 'email',\n",
    " 'ltrcomment',\n",
    " 'theme1',\n",
    " 'theme2',\n",
    " 'theme3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df5=pd.melt(df4, id_vars=[ 'email', 'ltrcomment'], value_vars=['theme1', 'theme2', 'theme3'], var_name='theme', \n",
    "            value_name='themes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>ltrcomment</th>\n",
       "      <th>theme</th>\n",
       "      <th>themes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alain.z.cote@dgag.ca</td>\n",
       "      <td>Improve the quality, stability and integration...</td>\n",
       "      <td>theme1</td>\n",
       "      <td>Product_Quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>matt.merchant@ge.com</td>\n",
       "      <td>ITSM space is best for CA Still work to be don...</td>\n",
       "      <td>theme1</td>\n",
       "      <td>Product_Quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chris.schwind@firstdata.com</td>\n",
       "      <td>Service Assurance, Mainframe tools, Scheduling...</td>\n",
       "      <td>theme1</td>\n",
       "      <td>Product_Quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dominic.nguyen@ge.com</td>\n",
       "      <td>Needs to get product more stable and less bugs</td>\n",
       "      <td>theme1</td>\n",
       "      <td>Product_Quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mz1223@att.com</td>\n",
       "      <td>We primarily use Introscope under the APM suit...</td>\n",
       "      <td>theme1</td>\n",
       "      <td>Contracts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         email  \\\n",
       "0         alain.z.cote@dgag.ca   \n",
       "1         matt.merchant@ge.com   \n",
       "2  chris.schwind@firstdata.com   \n",
       "3        dominic.nguyen@ge.com   \n",
       "4               mz1223@att.com   \n",
       "\n",
       "                                          ltrcomment   theme           themes  \n",
       "0  Improve the quality, stability and integration...  theme1  Product_Quality  \n",
       "1  ITSM space is best for CA Still work to be don...  theme1  Product_Quality  \n",
       "2  Service Assurance, Mainframe tools, Scheduling...  theme1  Product_Quality  \n",
       "3     Needs to get product more stable and less bugs  theme1  Product_Quality  \n",
       "4  We primarily use Introscope under the APM suit...  theme1        Contracts  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df5['themes1'] = pd.Categorical.from_array(df5.themes).codes\n",
    "df5=df5.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2=df1[[u'FY14',\n",
    " u'FY15',\n",
    " u'FY16',\n",
    " 'DM/INF',\n",
    " 'END_USER',\n",
    " u'Q1',\n",
    " u'Q2',\n",
    " u'Q3',\n",
    " u'Q4',\n",
    " u'Existing_Enterprise',\n",
    " u'Growth',\n",
    " u'Named',\n",
    " u'New_Enterprise',\n",
    " u'Platinum',\n",
    " 'email',\n",
    " 'geo',\n",
    " 'segment',\n",
    " 'role2',\n",
    " 'ltr',\n",
    " 'acctmgt',\n",
    " 'licensecontract',\n",
    " 'bestpractice',\n",
    " 'implement',\n",
    " 'productqual',\n",
    " 'functionality',\n",
    " 'easeofuse',\n",
    " 'techsupport',\n",
    " 'fiscalyear',\n",
    " 'quarter',\n",
    " 'theme1',\n",
    " 'theme2',\n",
    " 'theme3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'FY14',\n",
       " u'FY15',\n",
       " u'FY16',\n",
       " 'DM/INF',\n",
       " 'END_USER',\n",
       " u'Q1',\n",
       " u'Q2',\n",
       " u'Q3',\n",
       " u'Q4',\n",
       " u'Existing_Enterprise',\n",
       " u'Growth',\n",
       " u'Named',\n",
       " u'New_Enterprise',\n",
       " u'Platinum',\n",
       " 'email',\n",
       " 'geo',\n",
       " 'segment',\n",
       " 'role2',\n",
       " 'ltr',\n",
       " 'acctmgt',\n",
       " 'licensecontract',\n",
       " 'bestpractice',\n",
       " 'implement',\n",
       " 'productqual',\n",
       " 'functionality',\n",
       " 'easeofuse',\n",
       " 'techsupport',\n",
       " 'fiscalyear',\n",
       " 'quarter',\n",
       " 'theme1',\n",
       " 'theme2',\n",
       " 'theme3']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'FY14',\n",
       " u'FY15',\n",
       " u'FY16',\n",
       " 'DM/INF',\n",
       " 'END_USER',\n",
       " u'Q1',\n",
       " u'Q2',\n",
       " u'Q3',\n",
       " u'Q4',\n",
       " u'Existing_Enterprise',\n",
       " u'Growth',\n",
       " u'Named',\n",
       " u'New_Enterprise',\n",
       " u'Platinum',\n",
       " 'email',\n",
       " 'geo',\n",
       " 'segment',\n",
       " 'role2',\n",
       " 'ltr',\n",
       " 'acctmgt',\n",
       " 'licensecontract',\n",
       " 'bestpractice',\n",
       " 'implement',\n",
       " 'productqual',\n",
       " 'functionality',\n",
       " 'easeofuse',\n",
       " 'techsupport',\n",
       " 'fiscalyear',\n",
       " 'quarter',\n",
       " 'ltrcomment',\n",
       " 'ltr_comment_theme1',\n",
       " 'ltr_comment_theme2',\n",
       " 'ltr_comment_theme3',\n",
       " 'theme1',\n",
       " 'theme2',\n",
       " 'theme3',\n",
       " 'Support',\n",
       " 'Account_Team_Relationship',\n",
       " 'Contracts',\n",
       " 'Product Scope',\n",
       " 'Product_Quality',\n",
       " 'Services',\n",
       " 'Brand',\n",
       " 'Implementations/Upgrades',\n",
       " 'Product_Usability',\n",
       " 'Documentation',\n",
       " 'Partners',\n",
       " 'Self_service/KnowledgeBase/Website',\n",
       " 'Unable to recommend']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3=pd.melt(df2, id_vars=[ 'email','FY16','END_USER', 'Platinum'\n",
    "                         ], value_vars=['theme1', 'theme2', 'theme3'], var_name='theme', value_name='themes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df4=df3.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product_Quality              2350\n",
       "Support                      1351\n",
       "Account_Team_Relationship    1024\n",
       "Contracts                     564\n",
       "Implementations/Upgrades      252\n",
       "Brand                         129\n",
       "Services                      122\n",
       "Unable to recommend             3\n",
       "Name: themes, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4['themes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'Platinum',\n",
    "#  'ltr',\n",
    "#  'acctmgt',\n",
    "#  'licensecontract',\n",
    "#  'bestpractice',\n",
    "#  'implement',\n",
    "#  'productqual',\n",
    "#  'functionality',\n",
    "#  'easeofuse',\n",
    "#  'techsupport'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>FY16</th>\n",
       "      <th>END_USER</th>\n",
       "      <th>Platinum</th>\n",
       "      <th>theme</th>\n",
       "      <th>themes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alain.z.cote@dgag.ca</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>theme1</td>\n",
       "      <td>Product_Quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>matt.merchant@ge.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>theme1</td>\n",
       "      <td>Product_Quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chris.schwind@firstdata.com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>theme1</td>\n",
       "      <td>Product_Quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dominic.nguyen@ge.com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>theme1</td>\n",
       "      <td>Product_Quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mz1223@att.com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>theme1</td>\n",
       "      <td>Contracts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         email  FY16  END_USER  Platinum   theme  \\\n",
       "0         alain.z.cote@dgag.ca     0         1         0  theme1   \n",
       "1         matt.merchant@ge.com     0         0         1  theme1   \n",
       "2  chris.schwind@firstdata.com     0         1         1  theme1   \n",
       "3        dominic.nguyen@ge.com     0         1         1  theme1   \n",
       "4               mz1223@att.com     0         1         1  theme1   \n",
       "\n",
       "            themes  \n",
       "0  Product_Quality  \n",
       "1  Product_Quality  \n",
       "2  Product_Quality  \n",
       "3  Product_Quality  \n",
       "4        Contracts  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5795"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product_Quality              2350\n",
       "Support                      1351\n",
       "Account_Team_Relationship    1024\n",
       "Contracts                     564\n",
       "Implementations/Upgrades      252\n",
       "Brand                         129\n",
       "Services                      122\n",
       "Unable to recommend             3\n",
       "Name: themes, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4['themes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df4 = df4[(df4.themes != 'Unable to recommend') & (df4.themes != 'Services') & \n",
    "           (df4.themes != 'Implementations/Upgrades') & (df4.themes != 'Product Mentions') \n",
    "          & (df4.themes != 'Product Usability') & (df4.themes != 'Brand') & (df4.themes != 'Contracts')   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product_Quality              2350\n",
       "Support                      1351\n",
       "Account_Team_Relationship    1024\n",
       "Name: themes, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4['themes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4['themes1'] = pd.Categorical.from_array(df4.themes).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2350\n",
       "2    1351\n",
       "0    1024\n",
       "Name: themes1, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X=df4.iloc[:,1:3]\n",
    "y=df4.iloc[:,6]\n",
    "# create 80%-20% train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = [accuracy_score, precision_score, recall_score]\n",
    "models = [SVC(probability = True)]\n",
    "def get_metrics(features, outcome, test=0.2):\n",
    "    \n",
    "    train_X, test_X, train_y, test_y = train_test_split(features, outcome, test_size = test, random_state=444)\n",
    "    \n",
    "    # create empty lists\n",
    "    SVMC = []\n",
    "    RandomForest = []\n",
    "   \n",
    "    # list of lists\n",
    "    lists = [SVMC]    \n",
    "    # populate lists with scores of each scoring method\n",
    "    for i, model in enumerate(models):\n",
    "        for score in scores:\n",
    "            est = model\n",
    "            est.fit(train_X, train_y)\n",
    "            pred = est.predict(test_X)\n",
    "            lists[i].append(score(test_y, pred))\n",
    "        \n",
    "    # create a dataframe which aggregates the lists\n",
    "    scores_df = pd.DataFrame(data = [SVMC])\n",
    "    scores_df.index = [\"SVMC\"]\n",
    "    scores_df.columns = [\"Accuracy\", \"Precision\", \"Recall\"]\n",
    "    return scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = [accuracy_score, precision_score, recall_score]\n",
    "models = [RandomForestClassifier()]\n",
    "def get_metrics1(features, outcome, test=0.2):\n",
    "    \n",
    "    train_X, test_X, train_y, test_y = train_test_split(features, outcome, test_size = test, random_state=444)\n",
    "    \n",
    "    # create empty lists\n",
    "    RandomForest = []\n",
    "   \n",
    "    # list of lists\n",
    "    lists = [RandomForest]    \n",
    "    # populate lists with scores of each scoring method\n",
    "    for i, model in enumerate(models):\n",
    "        for score in scores:\n",
    "            est = model\n",
    "            est.fit(train_X, train_y)\n",
    "            pred = est.predict(test_X)\n",
    "            lists[i].append(score(test_y, pred))\n",
    "        \n",
    "    # create a dataframe which aggregates the lists\n",
    "    scores_df = pd.DataFrame(data = [ RandomForest])\n",
    "    scores_df.index = [\"RandomForest\"]\n",
    "    scores_df.columns = [\"Accuracy\", \"Precision\", \"Recall\"]\n",
    "    return scores_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shani16/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/shani16/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/shani16/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1304: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVMC</th>\n",
       "      <td>0.493122</td>\n",
       "      <td>0.243169</td>\n",
       "      <td>0.493122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy  Precision    Recall\n",
       "SVMC  0.493122   0.243169  0.493122"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(X,y, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shani16/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/shani16/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1304: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.975</td>\n",
       "      <td>0.967722</td>\n",
       "      <td>0.963889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Accuracy  Precision    Recall\n",
       "RandomForest     0.975   0.967722  0.963889"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics1(X,y, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=9, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import grid_search\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "parameters = {'max_features':['sqrt', 'log2', 10],\n",
    "              'max_depth':[5, 7, 9]}\n",
    "\n",
    "clf_grid = grid_search.GridSearchCV(rf, parameters, n_jobs=-1)\n",
    "clf_grid.fit(X_train, y_train)\n",
    "clf_grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shani16/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/shani16/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1304: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n"
     ]
    }
   ],
   "source": [
    "est=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=9, max_features='sqrt', max_leaf_nodes=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "est.fit(X_train, y_train)\n",
    "pred = est.predict(X_test)\n",
    "pre=precision_score(pred, y_test)\n",
    "recall= recall_score(pred, y_test)\n",
    "accuracy= accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97374446596173736"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97333333333333338"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97333333333333338"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(model,x_train,y_train,x_test,y_test,cmap=plt.cm.Blues):\n",
    "    y_pred = model.fit(x_train, y_train).predict(x_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    print(cm_normalized)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(cm_normalized, interpolation='nearest', cmap=cmap)\n",
    "    plt.title('Normalized Confusion Matrix: {}')\n",
    "    plt.colorbar()\n",
    "    plt.xticks([0,1],['Negative diagnosis','Positive Diagnosis'])\n",
    "    plt.yticks([0,1],['Negative diagnosis','Positive Diagnosis'])\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(est,X_train,y_train,X_test,y_test,cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df4['themes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Feature Importance\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "# load the iris datasets\n",
    "# fit an Extra Trees model to the data\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X, y)\n",
    "# display the relative importance of each attribute\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Recursive Feature Elimination\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# load the iris datasets\n",
    "dataset = datasets.load_iris()\n",
    "# create a base classifier used to evaluate a subset of attributes\n",
    "model = LogisticRegression()\n",
    "# create the RFE model and select 3 attributes\n",
    "rfe = RFE(model, 3)\n",
    "rfe = rfe.fit(X,y)\n",
    "# summarize the selection of the attributes\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "model = RandomForestClassifier()\n",
    "parameters = [{\"n_estimators\": [250, 500, 1000]}]\n",
    " \n",
    "# Returns the best configuration for a model using crosvalidation\n",
    "# and grid search\n",
    "def best_config(model, parameters, train_instances, judgements):\n",
    "    clf = GridSearchCV(model, parameters, cv=5,\n",
    "                       scoring=\"accuracy\", verbose=5, n_jobs=4)\n",
    "    clf.fit(train_instances, judgements)\n",
    "    best_estimator = clf.best_estimator_\n",
    "    print('Best hyperparameters: ' + str(clf.best_params_))\n",
    " \n",
    "    return [str(clf.best_params_), clf.best_score_,\n",
    "            best_estimator]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_config(model, parameters, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X=df5.iloc[:,1]\n",
    "y=df5.iloc[:,4]\n",
    "# create 80%-20% train-test split\n",
    "X_train_tdf, X_test_tdf, y_train_tdf, y_test_tdf = train_test_split(X, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk.stem\n",
    "english_stemmer = nltk.stem.SnowballStemmer('english')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "class StemmedTfidfVectorizer(CountVectorizer):\n",
    "\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(CountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: (english_stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "vectorizer = StemmedTfidfVectorizer(min_df=0, max_df=0.5, ngram_range=(1, 5),\n",
    "                                    stop_words=stopwords, decode_error='ignore'\n",
    "                                    )\n",
    "X_train_counts = vectorizer.fit_transform(X_train_tdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naives Bayes Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train_tdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_new_counts = vectorizer.transform(X_test)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),  ('tfidf', TfidfTransformer()),('clf', MultinomialNB()),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_clf = text_clf.fit(X_train_tdf, y_train_tdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "docs_test = X_test\n",
    "predicted = text_clf.predict(X_test_tdf)\n",
    "np.mean(predicted == y_test_tdf)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, predicted))\n",
    "#metrics.confusion_matrix(y_test, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from brew.base import Ensemble\n",
    "from brew.base import EnsembleClassifier\n",
    "from brew.combination import  Combiner\n",
    "\n",
    "# create your Ensemble\n",
    "clfs = your_list_of_classifiers # [clf1, clf2]\n",
    "ens = Ensemble(classifiers = clfs)\n",
    "\n",
    "# create your Combiner\n",
    "# the rules can be 'majority_vote', 'max', 'min', 'mean' or 'median'\n",
    "comb = Combiner(rule='majority_vote')\n",
    "\n",
    "# now create your ensemble classifier\n",
    "ensemble_clf = EnsembleClassifier(ensemble=ens, combiner=comb)\n",
    "ensemble_clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
