{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import logging\n",
    "from gensim import corpora, models, similarities\n",
    "from pprint import pprint\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "from sklearn import feature_extraction\n",
    "import mpld3\n",
    "import lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shani16/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2902: DtypeWarning: Columns (5,7,10,11,13,14,15,16,17,22,24,25,26,27,29,32,33,34,35,36,39,40,41,44,45,57,58,61,68,77,78,79,80,82,107,108,144,145,146,147,154,155,156,157,158,160,161,162,163,164,166,168,171,173,174,175,176,177,179) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "ltr=pd.read_csv('/Users/shani16/fletcher/data/ltr2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ltr.loc[ltr['Translation to English for: LTR Comment'].isnull(),'Translation to English for: LTR Comment'] = ltr['LTR Comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ltr=ltr[(ltr['Survey Type'] == \"Insights\")]\n",
    "det= ltr[(ltr['LTR'] <= 6)]\n",
    "df=det[['email', 'Translation to English for: LTR Comment']]\n",
    "df.columns=['email', 'comment']\n",
    "df=pd.DataFrame(df.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mban@bpba.com.ar</td>\n",
       "      <td>I would be interested they can solucuonar inco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>simone.barbosa@lojasrenner.com.br</td>\n",
       "      <td>Meet as soon as the so-called demands. Improve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mdunn@wellington.com</td>\n",
       "      <td>It has been a very unsatisfactory experience w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>andre_doles@gap.com</td>\n",
       "      <td>Not leave your customers hanging when they nee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cecilia.shea@sabic-ip.com</td>\n",
       "      <td>Contract Management, strategic planning &amp; regu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                email  \\\n",
       "0                    mban@bpba.com.ar   \n",
       "6   simone.barbosa@lojasrenner.com.br   \n",
       "8                mdunn@wellington.com   \n",
       "9                 andre_doles@gap.com   \n",
       "10          cecilia.shea@sabic-ip.com   \n",
       "\n",
       "                                              comment  \n",
       "0   I would be interested they can solucuonar inco...  \n",
       "6   Meet as soon as the so-called demands. Improve...  \n",
       "8   It has been a very unsatisfactory experience w...  \n",
       "9   Not leave your customers hanging when they nee...  \n",
       "10  Contract Management, strategic planning & regu...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1=df1.replace({'\\r': ' '}, regex=True)\n",
    "df1=df1.replace({'\\xff': ' '}, regex=True)\n",
    "df1=df1.replace({'\\xfa': ' '}, regex=True)\n",
    "df1=df1.replace({'\\x84': ' '}, regex=True)\n",
    "df1=df1.replace({'\\x94': ' '}, regex=True)\n",
    "df1=df1.replace({'\\x87': ' '}, regex=True)\n",
    "df1=df1.replace({'\\xc60': ' '}, regex=True)\n",
    "df1=df1.replace({'\\xa2lio': ' '}, regex=True)\n",
    "df1=df1.replace({'\\xc6o': ' '}, regex=True)\n",
    "# df2=df1.comment.tolist()\n",
    "# tok=[nltk.sent_tokenize(s) for s in df2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mban@bpba.com.ar</td>\n",
       "      <td>I would be interested they can solucuonar inco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>simone.barbosa@lojasrenner.com.br</td>\n",
       "      <td>Meet as soon as the so-called demands. Improve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mdunn@wellington.com</td>\n",
       "      <td>It has been a very unsatisfactory experience w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>andre_doles@gap.com</td>\n",
       "      <td>Not leave your customers hanging when they nee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cecilia.shea@sabic-ip.com</td>\n",
       "      <td>Contract Management, strategic planning &amp; regu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                email  \\\n",
       "0                    mban@bpba.com.ar   \n",
       "6   simone.barbosa@lojasrenner.com.br   \n",
       "8                mdunn@wellington.com   \n",
       "9                 andre_doles@gap.com   \n",
       "10          cecilia.shea@sabic-ip.com   \n",
       "\n",
       "                                              comment  \n",
       "0   I would be interested they can solucuonar inco...  \n",
       "6   Meet as soon as the so-called demands. Improve...  \n",
       "8   It has been a very unsatisfactory experience w...  \n",
       "9   Not leave your customers hanging when they nee...  \n",
       "10  Contract Management, strategic planning & regu...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1['token']=df1['comment'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>comment</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mban@bpba.com.ar</td>\n",
       "      <td>I would be interested they can solucuonar inco...</td>\n",
       "      <td>[I, would, be, interested, they, can, solucuon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>simone.barbosa@lojasrenner.com.br</td>\n",
       "      <td>Meet as soon as the so-called demands. Improve...</td>\n",
       "      <td>[Meet, as, soon, as, the, so-called, demands, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mdunn@wellington.com</td>\n",
       "      <td>It has been a very unsatisfactory experience w...</td>\n",
       "      <td>[It, has, been, a, very, unsatisfactory, exper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>andre_doles@gap.com</td>\n",
       "      <td>Not leave your customers hanging when they nee...</td>\n",
       "      <td>[Not, leave, your, customers, hanging, when, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cecilia.shea@sabic-ip.com</td>\n",
       "      <td>Contract Management, strategic planning &amp; regu...</td>\n",
       "      <td>[Contract, Management, ,, strategic, planning,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                email  \\\n",
       "0                    mban@bpba.com.ar   \n",
       "6   simone.barbosa@lojasrenner.com.br   \n",
       "8                mdunn@wellington.com   \n",
       "9                 andre_doles@gap.com   \n",
       "10          cecilia.shea@sabic-ip.com   \n",
       "\n",
       "                                              comment  \\\n",
       "0   I would be interested they can solucuonar inco...   \n",
       "6   Meet as soon as the so-called demands. Improve...   \n",
       "8   It has been a very unsatisfactory experience w...   \n",
       "9   Not leave your customers hanging when they nee...   \n",
       "10  Contract Management, strategic planning & regu...   \n",
       "\n",
       "                                                token  \n",
       "0   [I, would, be, interested, they, can, solucuon...  \n",
       "6   [Meet, as, soon, as, the, so-called, demands, ...  \n",
       "8   [It, has, been, a, very, unsatisfactory, exper...  \n",
       "9   [Not, leave, your, customers, hanging, when, t...  \n",
       "10  [Contract, Management, ,, strategic, planning,...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_new = df1.groupby('email').token.apply(lambda x: pd.DataFrame(x.values[0])).reset_index().drop('level_1', axis = 1)\n",
    "df_new.columns = ['email','sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords += ['.', ',', '(', ')', \"'\", '\"', 'ca']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorizer=CountVectorizer(stop_words=stopwords)\n",
    "counts=count_vectorizer.fit_transform(df_new['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "count_vectorizer1=TfidfVectorizer(stop_words=stopwords)\n",
    "counts1=count_vectorizer1.fit_transform(df_new['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test=pd.DataFrame(df_new['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.to_csv('words.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00137422</th>\n",
       "      <th>06</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>10000</th>\n",
       "      <th>1000s</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>...</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>youd</th>\n",
       "      <th>youtube</th>\n",
       "      <th>youve</th>\n",
       "      <th>zeitl</th>\n",
       "      <th>zero</th>\n",
       "      <th>zone</th>\n",
       "      <th>zsecure</th>\n",
       "      <th>zuk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 4587 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00137422  06  10  100  1000  10000  1000s  11  12  13 ...   yesterday  yet  \\\n",
       "0         0   0   0    0     0      0      0   0   0   0 ...           0    0   \n",
       "\n",
       "   youd  youtube  youve  zeitl  zero  zone  zsecure  zuk  \n",
       "0     0        0      0      0     0     0        0    0  \n",
       "\n",
       "[1 rows x 4587 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature= counts.toarray()\n",
    "feature_df = pd.DataFrame(feature, columns=count_vectorizer.get_feature_names())\n",
    "feature_df[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shani16/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3112</th>\n",
       "      <td>products</td>\n",
       "      <td>546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4009</th>\n",
       "      <td>support</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3106</th>\n",
       "      <td>product</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>better</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>improve</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2183</th>\n",
       "      <td>issues</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4385</th>\n",
       "      <td>us</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4390</th>\n",
       "      <td>use</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>customer</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4544</th>\n",
       "      <td>work</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4177</th>\n",
       "      <td>time</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>software</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3167</th>\n",
       "      <td>provide</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2654</th>\n",
       "      <td>needs</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4563</th>\n",
       "      <td>would</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3680</th>\n",
       "      <td>service</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2650</th>\n",
       "      <td>need</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2437</th>\n",
       "      <td>make</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>get</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2673</th>\n",
       "      <td>new</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  freq\n",
       "3112  products   546\n",
       "4009   support   449\n",
       "3106   product   418\n",
       "476     better   258\n",
       "1983   improve   243\n",
       "2183    issues   151\n",
       "4385        us   146\n",
       "4390       use   144\n",
       "1004  customer   144\n",
       "4544      work   135\n",
       "4177      time   128\n",
       "3795  software   128\n",
       "3167   provide   126\n",
       "2654     needs   126\n",
       "4563     would   125\n",
       "3680   service   111\n",
       "2650      need   109\n",
       "2437      make   109\n",
       "1753       get   108\n",
       "2673       new   106"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequency = feature_df.sum().reset_index()\n",
    "word_frequency.columns=['word', 'freq']\n",
    "\n",
    "word_frequency=word_frequency.sort(columns='freq', ascending= False)\n",
    "word_frequency[:20]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature1= counts1.toarray()\n",
    "feature_df1 = pd.DataFrame(feature1, columns=count_vectorizer.get_feature_names())\n",
    "feature_df1[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_frequency1 = feature_df1.sum().reset_index()\n",
    "word_frequency1.columns=['word', 'freq']\n",
    "\n",
    "word_frequency1=word_frequency1.sort(columns='freq', ascending= False)\n",
    "word_frequency1[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusters K Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "model = KMeans (n_clusters=30, init= 'k-means++', max_iter=100, n_init=1, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = KMeans (n_clusters=11, init= 'k-means++', max_iter=100, n_init=1 ,verbose=3)\n",
    "model.fit(counts) #add sparse matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sorting in descending order ie: -1\n",
    "#giving top ten words ie: :10\n",
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = count_vectorizer.get_feature_names()\n",
    "for i in range(10):\n",
    "   print \"Cluster %d:\" % i,\n",
    "   for ind in order_centroids[i, :10]:\n",
    "       print ' %s' % terms[ind],\n",
    "   print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model1 = KMeans (n_clusters=11, init= 'k-means++', max_iter=100, n_init=1, verbose=3)\n",
    "model1.fit(counts1) #add sparse matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clusters1=pd.Series(model1.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sorting in descending order ie: -1\n",
    "#giving top ten words ie: :10\n",
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = model1.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = count_vectorizer.get_feature_names()\n",
    "for i in range(9):\n",
    "   print \"Cluster %d:\" % i,\n",
    "   for ind in order_centroids[i, :10]:\n",
    "       print ' %s' % terms[ind],\n",
    "   print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_new['clusters1']=clusters1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cluster_1 = model.transform(counts)[:, 0]\n",
    "# ind = np.argsort(cluster_1)[::-1][:50]\n",
    "# df_new.iloc[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cluster_1 = model.transform(counts)[:, 0]\n",
    "# ind = np.argsort(cluster_1)[::-1][:50]\n",
    "# df_new.iloc[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped = df_new.groupby('clusters1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf-idf features for NMF...\n",
      "done in 0.460s.\n",
      "Extracting tf features for LDA...\n",
      "done in 0.435s.\n",
      "Fitting the NMF model with tf-idf features,n_samples=2000 and n_features=1000...\n",
      "done in 2.221s.\n",
      "\n",
      "Topics in NMF model:\n",
      "Topic #0:\n",
      "ca software zuk facing facility facilitate extremely externally external extent factor extensive extensions express exposure explanation fact factors feature fail\n",
      "Topic #1:\n",
      "products solutions zuk extent facility facilitate extremely externally external extensions extensive fact express exposure explanation explain facing factors factor expertise\n",
      "Topic #2:\n",
      "support service knowledge facilitate extremely externally external extent extensive extensions facing express exposure explanation explain experts facility fact expert factor\n",
      "Topic #3:\n",
      "product code answering favorable fault experts explain explanation exposure express extensions extensive extent external externally extremely facilitate facility facing expertise\n",
      "Topic #4:\n",
      "improve enhance external facing facility facilitate extremely externally zuk fact extensive extensions express exposure explanation explain extent factors factor fail\n",
      "Topic #5:\n",
      "better stricter extent facing facility facilitate extremely externally external extensive factor extensions express exposure explanation explain fact zuk experts fail\n",
      "Topic #6:\n",
      "issues challenges explanation exposure express extensions extensive extent external externally extremely facilitate facility facing fact factor factors experts fail failed\n",
      "Topic #7:\n",
      "customer pro external facing facility facilitate extremely externally zuk fact extensive extensions express exposure explanation explain extent factor expertise factors\n",
      "Topic #8:\n",
      "needs solutions requirements zuk extensive facilitate extremely externally external extent extensions facing express exposure explanation explain facility fact expertise factor\n",
      "Topic #9:\n",
      "use ease pay zuk externally facing facility facilitate extremely external factor extent extensive extensions express exposure explanation fact factors experts\n",
      "\n",
      "Fitting LDA models with tf features, n_samples=2000 and n_features=1000...\n",
      "done in 19.396s.\n",
      "\n",
      "Topics in LDA model:\n",
      "Topic #0:\n",
      "product pricing technologies environment recommend sales end cas focus model want implement easier response months actually existing manager changes offer\n",
      "Topic #1:\n",
      "support better use software management experience based licensing contract long know way think set continue easy spectrum environments delivery term\n",
      "Topic #2:\n",
      "customers working user difficult problems lack problem project available roadmap client reduce data things manage area enterprise start times able\n",
      "Topic #3:\n",
      "business clarity information current process improved ensure high technology point improvement level apm function market stable line used order bugs\n",
      "Topic #4:\n",
      "products quality service technical account year engagement partner monitoring knowledge partners costs staff spend releases interface making believe production ppm\n",
      "Topic #5:\n",
      "work provide need solutions like tools tool years help understand upgrade best relationship version maintenance great understanding view lower multiple\n",
      "Topic #6:\n",
      "ca issues team functionality people case ability really professional change increase provided required cloud run create usability integrated resource appear\n",
      "Topic #7:\n",
      "improve time solution implementation price does features resources having sure single sell strategic release enhancement terms stability cases challenges approach\n",
      "Topic #8:\n",
      "make new good services cost integration 30 just requirements involved performance 20126 training 2012 mainframe currently build different testing clear\n",
      "Topic #9:\n",
      "customer needs company value dont development deliver open lot issue documentation meet using contact large clients little feel fix organization\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "n_samples = 2000\n",
    "n_features = 1000\n",
    "n_topics = 10\n",
    "n_top_words = 20\n",
    "\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()\n",
    "\n",
    "\n",
    "# Load the 20 newsgroups dataset and vectorize it. We use a few heuristics\n",
    "# to filter out useless terms early on: the posts are stripped of headers,\n",
    "# footers and quoted replies, and common English words, words occurring in\n",
    "# only one document or in at least 95% of the documents are removed.\n",
    "\n",
    "\n",
    "# data_samples = dataset.data\n",
    "# print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "# # Use tf-idf features for NMF.\n",
    "print(\"Extracting tf-idf features for NMF...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, #max_features=n_features,\n",
    "                                   stop_words='english')\n",
    "t0 = time()\n",
    "tfidf = tfidf_vectorizer.fit_transform(df_new['sentence'])\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "# Use tf (raw term count) features for LDA.\n",
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=n_features,\n",
    "                                stop_words='english')\n",
    "t0 = time()\n",
    "tf = tf_vectorizer.fit_transform(df_new['sentence'])\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "# Fit the NMF model\n",
    "print(\"Fitting the NMF model with tf-idf features,\"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "t0 = time()\n",
    "nmf = NMF(n_components=n_topics, random_state=1, alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "exit()\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in NMF model:\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)\n",
    "\n",
    "print(\"Fitting LDA models with tf features, n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "lda = LatentDirichletAllocation(n_topics=n_topics, max_iter=5,\n",
    "                                learning_method='online', learning_offset=50.,\n",
    "                                random_state=0)\n",
    "t0 = time()\n",
    "lda.fit(tf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
